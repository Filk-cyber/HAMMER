{
  "metrics": {
    "weight_w": 0.1,
    "input_file": "/home/jiangjp/trace-idea/data/musique/musique_dev100ideal_with_reasoning_chains_modify_w01.json",
    "total_samples": 100,
    "exact_match": 0.44,
    "f1": 0.49946031746031744,
    "precision": 0.5241190476190476,
    "recall": 0.5062619047619047,
    "avg_max_log_prob": -5.928368180879263,
    "avg_max_prob": 0.4359620865366757,
    "avg_total_prob": 0.4524575530438492,
    "valid_max_prob_samples": 100,
    "invalid_max_prob_samples": 0,
    "avg_answer_count": 1.48,
    "avg_valid_answer_count": 1.48
  },
  "sample_info": [
    {
      "sample_idx": 0,
      "generated_answer": "March 1855",
      "gold_answers": [
        "April 1858"
      ],
      "reference_answer": "April 1858",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "April 1858": 0.33369214777306316
      },
      "individual_log_probs": {
        "April 1858": -1.097536424298596
      },
      "max_prob": 0.33369214777306316,
      "max_log_prob": -1.097536424298596,
      "best_answer": "April 1858",
      "total_prob": 0.33369214777306316,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 1,
      "generated_answer": "Stockholm Arlanda Airport.",
      "gold_answers": [
        "Stockholm Arlanda Airport",
        "Arlanda Airport",
        "ARN"
      ],
      "reference_answer": "Stockholm Arlanda Airport",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Stockholm Arlanda Airport": 0.8518080095719051,
        "Arlanda Airport": 0.11774598325605866,
        "ARN": 7.700702181058948e-07
      },
      "individual_log_probs": {
        "Stockholm Arlanda Airport": -0.16039411842393747,
        "Arlanda Airport": -2.1392256591425394,
        "ARN": -14.076784133911133
      },
      "max_prob": 0.8518080095719051,
      "max_log_prob": -0.16039411842393747,
      "best_answer": "Stockholm Arlanda Airport",
      "total_prob": 0.9695547628981819,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 2,
      "generated_answer": "Kapan",
      "gold_answers": [
        "Kapan"
      ],
      "reference_answer": "Kapan",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Kapan": 0.8229539128380816
      },
      "individual_log_probs": {
        "Kapan": -0.19485507885474362
      },
      "max_prob": 0.8229539128380816,
      "max_log_prob": -0.19485507885474362,
      "best_answer": "Kapan",
      "total_prob": 0.8229539128380816,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 3,
      "generated_answer": "Le Verrier and Adams",
      "gold_answers": [
        "Chinese"
      ],
      "reference_answer": "Chinese",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Chinese": 5.420193090920502e-07
      },
      "individual_log_probs": {
        "Chinese": -14.427964210510254
      },
      "max_prob": 5.420193090920502e-07,
      "max_log_prob": -14.427964210510254,
      "best_answer": "Chinese",
      "total_prob": 5.420193090920502e-07,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 4,
      "generated_answer": "1993",
      "gold_answers": [
        "1993"
      ],
      "reference_answer": "1993",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1993": 0.9960564335620316
      },
      "individual_log_probs": {
        "1993": -0.003951362799824665
      },
      "max_prob": 0.9960564335620316,
      "max_log_prob": -0.003951362799824665,
      "best_answer": "1993",
      "total_prob": 0.9960564335620316,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 5,
      "generated_answer": "1.7 million",
      "gold_answers": [
        "1.7 million"
      ],
      "reference_answer": "1.7 million",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1.7 million": 0.2594383484550484
      },
      "individual_log_probs": {
        "1.7 million": -1.349236182810273
      },
      "max_prob": 0.2594383484550484,
      "max_log_prob": -1.349236182810273,
      "best_answer": "1.7 million",
      "total_prob": 0.2594383484550484,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 6,
      "generated_answer": "34th",
      "gold_answers": [
        "34th"
      ],
      "reference_answer": "34th",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "34th": 0.9044304172165173
      },
      "individual_log_probs": {
        "34th": -0.10044990666210651
      },
      "max_prob": 0.9044304172165173,
      "max_log_prob": -0.10044990666210651,
      "best_answer": "34th",
      "total_prob": 0.9044304172165173,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 7,
      "generated_answer": "hotel and restaurant",
      "gold_answers": [
        "hotels",
        "Hotel",
        "hotel"
      ],
      "reference_answer": "hotels",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "hotels": 0.0016733102881341558,
        "Hotel": 0.2161658819204889,
        "hotel": 0.5628088250303847
      },
      "individual_log_probs": {
        "hotels": -6.392951406072825,
        "Hotel": -1.5317091941833496,
        "hotel": -0.5748152732849121
      },
      "max_prob": 0.5628088250303847,
      "max_log_prob": -0.5748152732849121,
      "best_answer": "hotel",
      "total_prob": 0.7806480172390078,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 8,
      "generated_answer": "University of Nebraska",
      "gold_answers": [
        "University of Nebraska"
      ],
      "reference_answer": "University of Nebraska",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "University of Nebraska": 0.5794843736787217
      },
      "individual_log_probs": {
        "University of Nebraska": -0.5456165817449801
      },
      "max_prob": 0.5794843736787217,
      "max_log_prob": -0.5456165817449801,
      "best_answer": "University of Nebraska",
      "total_prob": 0.5794843736787217,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 9,
      "generated_answer": "Anglican Church of Canada",
      "gold_answers": [
        "Anglican Church of Canada"
      ],
      "reference_answer": "Anglican Church of Canada",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Anglican Church of Canada": 0.6823493080550037
      },
      "individual_log_probs": {
        "Anglican Church of Canada": -0.3822135703602214
      },
      "max_prob": 0.6823493080550037,
      "max_log_prob": -0.3822135703602214,
      "best_answer": "Anglican Church of Canada",
      "total_prob": 0.6823493080550037,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 10,
      "generated_answer": "3",
      "gold_answers": [
        "three"
      ],
      "reference_answer": "three",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "three": 0.032850347949187224
      },
      "individual_log_probs": {
        "three": -3.415792942047119
      },
      "max_prob": 0.032850347949187224,
      "max_log_prob": -3.415792942047119,
      "best_answer": "three",
      "total_prob": 0.032850347949187224,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 11,
      "generated_answer": "Iván Duque",
      "gold_answers": [
        "Iván Duque"
      ],
      "reference_answer": "Iván Duque",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Iván Duque": 0.9960498505841421
      },
      "individual_log_probs": {
        "Iván Duque": -0.00395797186274649
      },
      "max_prob": 0.9960498505841421,
      "max_log_prob": -0.00395797186274649,
      "best_answer": "Iván Duque",
      "total_prob": 0.9960498505841421,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 12,
      "generated_answer": "1898",
      "gold_answers": [
        "August 12, 1898"
      ],
      "reference_answer": "August 12, 1898",
      "em_score": 0.0,
      "f1_score": 0.5,
      "precision": 1.0,
      "recall": 0.3333333333333333,
      "individual_probs": {
        "August 12, 1898": 0.37746750429707016
      },
      "individual_log_probs": {
        "August 12, 1898": -0.9742707953305327
      },
      "max_prob": 0.37746750429707016,
      "max_log_prob": -0.9742707953305327,
      "best_answer": "August 12, 1898",
      "total_prob": 0.37746750429707016,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 13,
      "generated_answer": "Beijing",
      "gold_answers": [
        "Dorgon"
      ],
      "reference_answer": "Dorgon",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Dorgon": 1.8894638161686924e-09
      },
      "individual_log_probs": {
        "Dorgon": -20.08697274327278
      },
      "max_prob": 1.8894638161686924e-09,
      "max_log_prob": -20.08697274327278,
      "best_answer": "Dorgon",
      "total_prob": 1.8894638161686924e-09,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 14,
      "generated_answer": "Christians.",
      "gold_answers": [
        "a red cross on a white field",
        "Red Cross"
      ],
      "reference_answer": "a red cross on a white field",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "a red cross on a white field": 3.167523155472846e-14,
        "Red Cross": 2.2356543092783462e-08
      },
      "individual_log_probs": {
        "a red cross on a white field": -31.08324135839939,
        "Red Cross": -17.61614680290222
      },
      "max_prob": 2.2356543092783462e-08,
      "max_log_prob": -17.61614680290222,
      "best_answer": "Red Cross",
      "total_prob": 2.2356574768015017e-08,
      "answer_count": 2,
      "valid_answer_count": 2,
      "weight_w": 0.1
    },
    {
      "sample_idx": 15,
      "generated_answer": "Warner Bros.",
      "gold_answers": [
        "Warner Bros."
      ],
      "reference_answer": "Warner Bros.",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Warner Bros.": 0.9979413776644327
      },
      "individual_log_probs": {
        "Warner Bros.": -0.002060744211121346
      },
      "max_prob": 0.9979413776644327,
      "max_log_prob": -0.002060744211121346,
      "best_answer": "Warner Bros.",
      "total_prob": 0.9979413776644327,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 16,
      "generated_answer": "Syracuse University",
      "gold_answers": [
        "Syracuse University",
        "Cuse",
        "SU"
      ],
      "reference_answer": "Syracuse University",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Syracuse University": 0.9992367536283964,
        "Cuse": 7.305531627866006e-12,
        "SU": 1.0501122283072564e-07
      },
      "individual_log_probs": {
        "Syracuse University": -0.0007635377924088971,
        "Cuse": -25.64238929748535,
        "SU": -16.069198608398438
      },
      "max_prob": 0.9992367536283964,
      "max_log_prob": -0.0007635377924088971,
      "best_answer": "Syracuse University",
      "total_prob": 0.9992368586469247,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 17,
      "generated_answer": "Hong Kong",
      "gold_answers": [
        "1842"
      ],
      "reference_answer": "1842",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1842": 0.0038066369274676486
      },
      "individual_log_probs": {
        "1842": -5.571009175851941
      },
      "max_prob": 0.0038066369274676486,
      "max_log_prob": -5.571009175851941,
      "best_answer": "1842",
      "total_prob": 0.0038066369274676486,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 18,
      "generated_answer": "100,000",
      "gold_answers": [
        "KPA"
      ],
      "reference_answer": "KPA",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "KPA": 0.023233577604728353
      },
      "individual_log_probs": {
        "KPA": -3.7621567361056805
      },
      "max_prob": 0.023233577604728353,
      "max_log_prob": -3.7621567361056805,
      "best_answer": "KPA",
      "total_prob": 0.023233577604728353,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 19,
      "generated_answer": "Fleetwood Mac",
      "gold_answers": [
        "Fleetwood Mac"
      ],
      "reference_answer": "Fleetwood Mac",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Fleetwood Mac": 0.9998622084275733
      },
      "individual_log_probs": {
        "Fleetwood Mac": -0.00013780106655758573
      },
      "max_prob": 0.9998622084275733,
      "max_log_prob": -0.00013780106655758573,
      "best_answer": "Fleetwood Mac",
      "total_prob": 0.9998622084275733,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 20,
      "generated_answer": "Norway",
      "gold_answers": [
        "Norway",
        "NO",
        "NOR",
        "no"
      ],
      "reference_answer": "Norway",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Norway": 0.7673632459787213,
        "NO": 1.2156922974753985e-07,
        "NOR": 4.9092320299559537e-05,
        "no": 3.1815466627811087e-08
      },
      "individual_log_probs": {
        "Norway": -0.2647949965321459,
        "NO": -15.922781944274902,
        "NOR": -9.921807944774628,
        "no": -17.26331329345703
      },
      "max_prob": 0.7673632459787213,
      "max_log_prob": -0.2647949965321459,
      "best_answer": "Norway",
      "total_prob": 0.7674124916837173,
      "answer_count": 4,
      "valid_answer_count": 4,
      "weight_w": 0.1
    },
    {
      "sample_idx": 21,
      "generated_answer": "1953",
      "gold_answers": [
        "1953"
      ],
      "reference_answer": "1953",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1953": 0.98931738605357
      },
      "individual_log_probs": {
        "1953": -0.010740082710981369
      },
      "max_prob": 0.98931738605357,
      "max_log_prob": -0.010740082710981369,
      "best_answer": "1953",
      "total_prob": 0.98931738605357,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 22,
      "generated_answer": "27 BC",
      "gold_answers": [
        "establishment of the Roman Empire.",
        "Roman Empire"
      ],
      "reference_answer": "establishment of the Roman Empire.",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "establishment of the Roman Empire.": 7.046104051500322e-07,
        "Roman Empire": 0.00010477204991475697
      },
      "individual_log_probs": {
        "establishment of the Roman Empire.": -14.165620803691553,
        "Roman Empire": -9.163723520934582
      },
      "max_prob": 0.00010477204991475697,
      "max_log_prob": -9.163723520934582,
      "best_answer": "Roman Empire",
      "total_prob": 0.00010547666031990701,
      "answer_count": 2,
      "valid_answer_count": 2,
      "weight_w": 0.1
    },
    {
      "sample_idx": 23,
      "generated_answer": "Not mentioned in the context.",
      "gold_answers": [
        "Visva-Bharati University"
      ],
      "reference_answer": "Visva-Bharati University",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Visva-Bharati University": 6.3909045700073386e-09
      },
      "individual_log_probs": {
        "Visva-Bharati University": -18.868390018324135
      },
      "max_prob": 6.3909045700073386e-09,
      "max_log_prob": -18.868390018324135,
      "best_answer": "Visva-Bharati University",
      "total_prob": 6.3909045700073386e-09,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 24,
      "generated_answer": "Sicily",
      "gold_answers": [
        "1773"
      ],
      "reference_answer": "1773",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1773": 1.804101664935716e-10
      },
      "individual_log_probs": {
        "1773": -22.43578815460205
      },
      "max_prob": 1.804101664935716e-10,
      "max_log_prob": -22.43578815460205,
      "best_answer": "1773",
      "total_prob": 1.804101664935716e-10,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 25,
      "generated_answer": "Kurdistan.",
      "gold_answers": [
        "Kurdish people"
      ],
      "reference_answer": "Kurdish people",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Kurdish people": 0.016152358348027748
      },
      "individual_log_probs": {
        "Kurdish people": -4.125689212232828
      },
      "max_prob": 0.016152358348027748,
      "max_log_prob": -4.125689212232828,
      "best_answer": "Kurdish people",
      "total_prob": 0.016152358348027748,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 26,
      "generated_answer": "eastern tip",
      "gold_answers": [
        "eastern tip"
      ],
      "reference_answer": "eastern tip",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "eastern tip": 0.5331511966526651
      },
      "individual_log_probs": {
        "eastern tip": -0.628950224025175
      },
      "max_prob": 0.5331511966526651,
      "max_log_prob": -0.628950224025175,
      "best_answer": "eastern tip",
      "total_prob": 0.5331511966526651,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 27,
      "generated_answer": "Peter Grant and Swan Song Records.",
      "gold_answers": [
        "Peter Grant"
      ],
      "reference_answer": "Peter Grant",
      "em_score": 0.0,
      "f1_score": 0.5,
      "precision": 0.3333333333333333,
      "recall": 1.0,
      "individual_probs": {
        "Peter Grant": 0.9930869601262063
      },
      "individual_log_probs": {
        "Peter Grant": -0.006937045633094385
      },
      "max_prob": 0.9930869601262063,
      "max_log_prob": -0.006937045633094385,
      "best_answer": "Peter Grant",
      "total_prob": 0.9930869601262063,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 28,
      "generated_answer": "Asia",
      "gold_answers": [
        "Central Asia"
      ],
      "reference_answer": "Central Asia",
      "em_score": 0.0,
      "f1_score": 0.6666666666666666,
      "precision": 1.0,
      "recall": 0.5,
      "individual_probs": {
        "Central Asia": 0.00019670953140229076
      },
      "individual_log_probs": {
        "Central Asia": -8.533782377198804
      },
      "max_prob": 0.00019670953140229076,
      "max_log_prob": -8.533782377198804,
      "best_answer": "Central Asia",
      "total_prob": 0.00019670953140229076,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 29,
      "generated_answer": "Syracuse University",
      "gold_answers": [
        "Syracuse University",
        "Cuse",
        "SU"
      ],
      "reference_answer": "Syracuse University",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Syracuse University": 0.9993957895077622,
        "Cuse": 1.3583416620010112e-09,
        "SU": 1.2157722969494256e-07
      },
      "individual_log_probs": {
        "Syracuse University": -0.0006043931009571679,
        "Cuse": -20.417001247406006,
        "SU": -15.92271614074707
      },
      "max_prob": 0.9993957895077622,
      "max_log_prob": -0.0006043931009571679,
      "best_answer": "Syracuse University",
      "total_prob": 0.9993959124433336,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 30,
      "generated_answer": "Laura Kelly",
      "gold_answers": [
        "Laura Kelly"
      ],
      "reference_answer": "Laura Kelly",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Laura Kelly": 0.9988247998086618
      },
      "individual_log_probs": {
        "Laura Kelly": -0.001175891280581709
      },
      "max_prob": 0.9988247998086618,
      "max_log_prob": -0.001175891280581709,
      "best_answer": "Laura Kelly",
      "total_prob": 0.9988247998086618,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 31,
      "generated_answer": "United States",
      "gold_answers": [
        "United States",
        "America",
        "US of A",
        "US",
        "the United States"
      ],
      "reference_answer": "United States",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "United States": 0.7622903112032534,
        "America": 1.0838825593576538e-05,
        "US of A": 9.594146405534909e-13,
        "US": 7.347091092282937e-06,
        "the United States": 0.0022228431987247428
      },
      "individual_log_probs": {
        "United States": -0.27142781002112315,
        "America": -11.43237590789795,
        "US of A": -27.67245304584503,
        "US": -11.821206092834473,
        "the United States": -6.108968182374156
      },
      "max_prob": 0.7622903112032534,
      "max_log_prob": -0.27142781002112315,
      "best_answer": "United States",
      "total_prob": 0.7645313403196236,
      "answer_count": 5,
      "valid_answer_count": 5,
      "weight_w": 0.1
    },
    {
      "sample_idx": 32,
      "generated_answer": "Hon July Moyo",
      "gold_answers": [
        "Hon July Moyo"
      ],
      "reference_answer": "Hon July Moyo",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Hon July Moyo": 0.9494252754882201
      },
      "individual_log_probs": {
        "Hon July Moyo": -0.051898450627952286
      },
      "max_prob": 0.9494252754882201,
      "max_log_prob": -0.051898450627952286,
      "best_answer": "Hon July Moyo",
      "total_prob": 0.9494252754882201,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 33,
      "generated_answer": "Painter",
      "gold_answers": [
        "Italian painter"
      ],
      "reference_answer": "Italian painter",
      "em_score": 0.0,
      "f1_score": 0.6666666666666666,
      "precision": 1.0,
      "recall": 0.5,
      "individual_probs": {
        "Italian painter": 6.456533078386778e-08
      },
      "individual_log_probs": {
        "Italian painter": -16.555588245391846
      },
      "max_prob": 6.456533078386778e-08,
      "max_log_prob": -16.555588245391846,
      "best_answer": "Italian painter",
      "total_prob": 6.456533078386778e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 34,
      "generated_answer": "Alfred Lennon",
      "gold_answers": [
        "Alfred Lennon"
      ],
      "reference_answer": "Alfred Lennon",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Alfred Lennon": 0.6310417034380554
      },
      "individual_log_probs": {
        "Alfred Lennon": -0.4603833275978104
      },
      "max_prob": 0.6310417034380554,
      "max_log_prob": -0.4603833275978104,
      "best_answer": "Alfred Lennon",
      "total_prob": 0.6310417034380554,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 35,
      "generated_answer": "GALERIA Kaufhof",
      "gold_answers": [
        "KaDeWe"
      ],
      "reference_answer": "KaDeWe",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "KaDeWe": 0.025497514565720657
      },
      "individual_log_probs": {
        "KaDeWe": -3.6691742995790264
      },
      "max_prob": 0.025497514565720657,
      "max_log_prob": -3.6691742995790264,
      "best_answer": "KaDeWe",
      "total_prob": 0.025497514565720657,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 36,
      "generated_answer": "1960",
      "gold_answers": [
        "1960"
      ],
      "reference_answer": "1960",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1960": 0.9587367165170545
      },
      "individual_log_probs": {
        "1960": -0.04213878139842109
      },
      "max_prob": 0.9587367165170545,
      "max_log_prob": -0.04213878139842109,
      "best_answer": "1960",
      "total_prob": 0.9587367165170545,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 37,
      "generated_answer": "11",
      "gold_answers": [
        "September 25, 2014"
      ],
      "reference_answer": "September 25, 2014",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "September 25, 2014": 0.0006890279538988338
      },
      "individual_log_probs": {
        "September 25, 2014": -7.280228716077204
      },
      "max_prob": 0.0006890279538988338,
      "max_log_prob": -7.280228716077204,
      "best_answer": "September 25, 2014",
      "total_prob": 0.0006890279538988338,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 38,
      "generated_answer": "Laughery Creek",
      "gold_answers": [
        "Ohio River"
      ],
      "reference_answer": "Ohio River",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Ohio River": 0.0012370335870866243
      },
      "individual_log_probs": {
        "Ohio River": -6.6950390338897705
      },
      "max_prob": 0.0012370335870866243,
      "max_log_prob": -6.6950390338897705,
      "best_answer": "Ohio River",
      "total_prob": 0.0012370335870866243,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 39,
      "generated_answer": "1963",
      "gold_answers": [
        "1963"
      ],
      "reference_answer": "1963",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1963": 0.5528606035194941
      },
      "individual_log_probs": {
        "1963": -0.5926493824372301
      },
      "max_prob": 0.5528606035194941,
      "max_log_prob": -0.5926493824372301,
      "best_answer": "1963",
      "total_prob": 0.5528606035194941,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 40,
      "generated_answer": "EU-25",
      "gold_answers": [
        "Europe's most innovative country",
        "Europe"
      ],
      "reference_answer": "Europe's most innovative country",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Europe's most innovative country": 8.610248794471084e-09,
        "Europe": 0.005796711327399258
      },
      "individual_log_probs": {
        "Europe's most innovative country": -18.57031262293458,
        "Europe": -5.1504645347595215
      },
      "max_prob": 0.005796711327399258,
      "max_log_prob": -5.1504645347595215,
      "best_answer": "Europe",
      "total_prob": 0.005796719937648053,
      "answer_count": 2,
      "valid_answer_count": 2,
      "weight_w": 0.1
    },
    {
      "sample_idx": 41,
      "generated_answer": "$122,160",
      "gold_answers": [
        "$122,160"
      ],
      "reference_answer": "$122,160",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "$122,160": 0.987309087180647
      },
      "individual_log_probs": {
        "$122,160": -0.012772130334724352
      },
      "max_prob": 0.987309087180647,
      "max_log_prob": -0.012772130334724352,
      "best_answer": "$122,160",
      "total_prob": 0.987309087180647,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 42,
      "generated_answer": "World Health Organization",
      "gold_answers": [
        "The World Health Organization (WHO)",
        "WHO",
        "World Health Organization"
      ],
      "reference_answer": "The World Health Organization (WHO)",
      "em_score": 1.0,
      "f1_score": 0.8571428571428571,
      "precision": 1.0,
      "recall": 0.75,
      "individual_probs": {
        "The World Health Organization (WHO)": 0.014180936670115904,
        "WHO": 0.29171104765937955,
        "World Health Organization": 0.6484064817366877
      },
      "individual_log_probs": {
        "The World Health Organization (WHO)": -4.255856704339294,
        "WHO": -1.2319915294647217,
        "World Health Organization": -0.43323749266119194
      },
      "max_prob": 0.6484064817366877,
      "max_log_prob": -0.43323749266119194,
      "best_answer": "World Health Organization",
      "total_prob": 0.9542984660661831,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 43,
      "generated_answer": "Sweden",
      "gold_answers": [
        "December 1917"
      ],
      "reference_answer": "December 1917",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "December 1917": 2.2768734781833267e-10
      },
      "individual_log_probs": {
        "December 1917": -22.203047709539533
      },
      "max_prob": 2.2768734781833267e-10,
      "max_log_prob": -22.203047709539533,
      "best_answer": "December 1917",
      "total_prob": 2.2768734781833267e-10,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 44,
      "generated_answer": "Sophia Akuffo",
      "gold_answers": [
        "Sophia Akuffo"
      ],
      "reference_answer": "Sophia Akuffo",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Sophia Akuffo": 0.9984437471932175
      },
      "individual_log_probs": {
        "Sophia Akuffo": -0.001557465026024829
      },
      "max_prob": 0.9984437471932175,
      "max_log_prob": -0.001557465026024829,
      "best_answer": "Sophia Akuffo",
      "total_prob": 0.9984437471932175,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 45,
      "generated_answer": "1920",
      "gold_answers": [
        "1895"
      ],
      "reference_answer": "1895",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1895": 0.0009145004045298865
      },
      "individual_log_probs": {
        "1895": -6.997132647782564
      },
      "max_prob": 0.0009145004045298865,
      "max_log_prob": -6.997132647782564,
      "best_answer": "1895",
      "total_prob": 0.0009145004045298865,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 46,
      "generated_answer": "The flag of the United States has 50 stars, not one star.",
      "gold_answers": [
        "represented the island of Puerto Rico",
        "PR",
        "Puerto Rico"
      ],
      "reference_answer": "represented the island of Puerto Rico",
      "em_score": 0.0,
      "f1_score": 0.13333333333333333,
      "precision": 0.1,
      "recall": 0.2,
      "individual_probs": {
        "represented the island of Puerto Rico": 2.7650358240179876e-14,
        "PR": 2.435198451704718e-07,
        "Puerto Rico": 4.474841778981788e-07
      },
      "individual_log_probs": {
        "represented the island of Puerto Rico": -31.21913771078107,
        "PR": -15.228067398071289,
        "Puerto Rico": -14.619624656508677
      },
      "max_prob": 4.474841778981788e-07,
      "max_log_prob": -14.619624656508677,
      "best_answer": "Puerto Rico",
      "total_prob": 6.910040507190089e-07,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 47,
      "generated_answer": "church",
      "gold_answers": [
        "temple, now a church",
        "Temple",
        "temple"
      ],
      "reference_answer": "temple, now a church",
      "em_score": 0.0,
      "f1_score": 0.5,
      "precision": 1.0,
      "recall": 0.3333333333333333,
      "individual_probs": {
        "temple, now a church": 3.165392597468306e-13,
        "Temple": 8.892683915663564e-05,
        "temple": 5.645445456549006e-05
      },
      "individual_log_probs": {
        "temple, now a church": -28.7813291175853,
        "Temple": -9.327696558233583,
        "temple": -9.782076358781524
      },
      "max_prob": 8.892683915663564e-05,
      "max_log_prob": -9.327696558233583,
      "best_answer": "Temple",
      "total_prob": 0.00014538129403866495,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 48,
      "generated_answer": "1974",
      "gold_answers": [
        "1909"
      ],
      "reference_answer": "1909",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1909": 7.970215021838104e-08
      },
      "individual_log_probs": {
        "1909": -16.344969272613525
      },
      "max_prob": 7.970215021838104e-08,
      "max_log_prob": -16.344969272613525,
      "best_answer": "1909",
      "total_prob": 7.970215021838104e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 49,
      "generated_answer": "21:30",
      "gold_answers": [
        "24 hours a day"
      ],
      "reference_answer": "24 hours a day",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "24 hours a day": 0.04155388060863873
      },
      "individual_log_probs": {
        "24 hours a day": -3.18076436592537
      },
      "max_prob": 0.04155388060863873,
      "max_log_prob": -3.18076436592537,
      "best_answer": "24 hours a day",
      "total_prob": 0.04155388060863873,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 50,
      "generated_answer": "Antarctica",
      "gold_answers": [
        "Antarctica"
      ],
      "reference_answer": "Antarctica",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Antarctica": 0.9988149867790631
      },
      "individual_log_probs": {
        "Antarctica": -0.0011857159042847343
      },
      "max_prob": 0.9988149867790631,
      "max_log_prob": -0.0011857159042847343,
      "best_answer": "Antarctica",
      "total_prob": 0.9988149867790631,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 51,
      "generated_answer": "Rhode Island",
      "gold_answers": [
        "Rhode Island Department of Transportation",
        "RIDOT"
      ],
      "reference_answer": "Rhode Island Department of Transportation",
      "em_score": 0.0,
      "f1_score": 0.5714285714285715,
      "precision": 1.0,
      "recall": 0.4,
      "individual_probs": {
        "Rhode Island Department of Transportation": 0.10613648605684876,
        "RIDOT": 0.06132842272679742
      },
      "individual_log_probs": {
        "Rhode Island Department of Transportation": -2.243029408811708,
        "RIDOT": -2.791511877483572
      },
      "max_prob": 0.10613648605684876,
      "max_log_prob": -2.243029408811708,
      "best_answer": "Rhode Island Department of Transportation",
      "total_prob": 0.16746490878364617,
      "answer_count": 2,
      "valid_answer_count": 2,
      "weight_w": 0.1
    },
    {
      "sample_idx": 52,
      "generated_answer": "No one signed the Declaration of Independence from the state where Keedy House is located, as Keedy House is located in Bo",
      "gold_answers": [
        "Charles Carroll"
      ],
      "reference_answer": "Charles Carroll",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Charles Carroll": 6.560562318212787e-08
      },
      "individual_log_probs": {
        "Charles Carroll": -16.539604425430298
      },
      "max_prob": 6.560562318212787e-08,
      "max_log_prob": -16.539604425430298,
      "best_answer": "Charles Carroll",
      "total_prob": 6.560562318212787e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 53,
      "generated_answer": "Monte Porzio Catone",
      "gold_answers": [
        "Castel Gandolfo"
      ],
      "reference_answer": "Castel Gandolfo",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Castel Gandolfo": 6.42950579401882e-07
      },
      "individual_log_probs": {
        "Castel Gandolfo": -14.25719797506872
      },
      "max_prob": 6.42950579401882e-07,
      "max_log_prob": -14.25719797506872,
      "best_answer": "Castel Gandolfo",
      "total_prob": 6.42950579401882e-07,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 54,
      "generated_answer": "None.",
      "gold_answers": [
        "Charles Carroll"
      ],
      "reference_answer": "Charles Carroll",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Charles Carroll": 0.0004580880700456246
      },
      "individual_log_probs": {
        "Charles Carroll": -7.68844909965992
      },
      "max_prob": 0.0004580880700456246,
      "max_log_prob": -7.68844909965992,
      "best_answer": "Charles Carroll",
      "total_prob": 0.0004580880700456246,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 55,
      "generated_answer": "Wendy Finerman",
      "gold_answers": [
        "Catherine Zeta-Jones"
      ],
      "reference_answer": "Catherine Zeta-Jones",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Catherine Zeta-Jones": 0.0005756438613511991
      },
      "individual_log_probs": {
        "Catherine Zeta-Jones": -7.460021384757624
      },
      "max_prob": 0.0005756438613511991,
      "max_log_prob": -7.460021384757624,
      "best_answer": "Catherine Zeta-Jones",
      "total_prob": 0.0005756438613511991,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 56,
      "generated_answer": "tsampa",
      "gold_answers": [
        "yak meat"
      ],
      "reference_answer": "yak meat",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "yak meat": 1.730873773602626e-06
      },
      "individual_log_probs": {
        "yak meat": -13.266884205513634
      },
      "max_prob": 1.730873773602626e-06,
      "max_log_prob": -13.266884205513634,
      "best_answer": "yak meat",
      "total_prob": 1.730873773602626e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 57,
      "generated_answer": "London Breed",
      "gold_answers": [
        "former Acting Mayor London Breed",
        "London Breed"
      ],
      "reference_answer": "former Acting Mayor London Breed",
      "em_score": 1.0,
      "f1_score": 0.5714285714285715,
      "precision": 1.0,
      "recall": 0.4,
      "individual_probs": {
        "former Acting Mayor London Breed": 2.430116650491817e-13,
        "London Breed": 0.9994666647032876
      },
      "individual_log_probs": {
        "former Acting Mayor London Breed": -29.045666948404687,
        "London Breed": -0.0005334775705705397
      },
      "max_prob": 0.9994666647032876,
      "max_log_prob": -0.0005334775705705397,
      "best_answer": "London Breed",
      "total_prob": 0.9994666647035306,
      "answer_count": 2,
      "valid_answer_count": 2,
      "weight_w": 0.1
    },
    {
      "sample_idx": 58,
      "generated_answer": "Lewis Range",
      "gold_answers": [
        "Rocky Mountains"
      ],
      "reference_answer": "Rocky Mountains",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Rocky Mountains": 8.646984165720116e-05
      },
      "individual_log_probs": {
        "Rocky Mountains": -9.355714856181294
      },
      "max_prob": 8.646984165720116e-05,
      "max_log_prob": -9.355714856181294,
      "best_answer": "Rocky Mountains",
      "total_prob": 8.646984165720116e-05,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 59,
      "generated_answer": "Tan Son Nhat International Airport",
      "gold_answers": [
        "Tân Sơn Nhất International Airport",
        "SGN",
        "Tan Son Nhat International Airport"
      ],
      "reference_answer": "Tân Sơn Nhất International Airport",
      "em_score": 1.0,
      "f1_score": 0.4000000000000001,
      "precision": 0.4,
      "recall": 0.4,
      "individual_probs": {
        "Tân Sơn Nhất International Airport": 1.7439342823800655e-05,
        "SGN": 0.3630303972725142,
        "Tan Son Nhat International Airport": 0.6276835534965022
      },
      "individual_log_probs": {
        "Tân Sơn Nhất International Airport": -10.956781822314952,
        "SGN": -1.0132687091804655,
        "Tan Son Nhat International Airport": -0.4657191352182508
      },
      "max_prob": 0.6276835534965022,
      "max_log_prob": -0.4657191352182508,
      "best_answer": "Tan Son Nhat International Airport",
      "total_prob": 0.9907313901118402,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 60,
      "generated_answer": "Mariner 10 and Voyager probes.",
      "gold_answers": [
        "Voyager probes"
      ],
      "reference_answer": "Voyager probes",
      "em_score": 0.0,
      "f1_score": 0.5714285714285715,
      "precision": 0.4,
      "recall": 1.0,
      "individual_probs": {
        "Voyager probes": 0.27752600579524794
      },
      "individual_log_probs": {
        "Voyager probes": -1.2818406356091145
      },
      "max_prob": 0.27752600579524794,
      "max_log_prob": -1.2818406356091145,
      "best_answer": "Voyager probes",
      "total_prob": 0.27752600579524794,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 61,
      "generated_answer": "American Idol",
      "gold_answers": [
        "American Idol"
      ],
      "reference_answer": "American Idol",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "American Idol": 0.9998877164349503
      },
      "individual_log_probs": {
        "American Idol": -0.00011228986932110274
      },
      "max_prob": 0.9998877164349503,
      "max_log_prob": -0.00011228986932110274,
      "best_answer": "American Idol",
      "total_prob": 0.9998877164349503,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 62,
      "generated_answer": "6th-century",
      "gold_answers": [
        "5th–6th centuries",
        "6th century",
        "6th-century"
      ],
      "reference_answer": "5th–6th centuries",
      "em_score": 1.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "5th–6th centuries": 6.64472976211778e-09,
        "6th century": 0.33042288605322834,
        "6th-century": 0.33986246857083374
      },
      "individual_log_probs": {
        "5th–6th centuries": -18.829441813461017,
        "6th century": -1.1073819720186293,
        "6th-century": -1.0792142474092543
      },
      "max_prob": 0.33986246857083374,
      "max_log_prob": -1.0792142474092543,
      "best_answer": "6th-century",
      "total_prob": 0.6702853612687918,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 63,
      "generated_answer": "63 BC",
      "gold_answers": [
        "March 44 BC"
      ],
      "reference_answer": "March 44 BC",
      "em_score": 0.0,
      "f1_score": 0.4,
      "precision": 0.5,
      "recall": 0.3333333333333333,
      "individual_probs": {
        "March 44 BC": 1.8422715630008965e-07
      },
      "individual_log_probs": {
        "March 44 BC": -15.507096295652445
      },
      "max_prob": 1.8422715630008965e-07,
      "max_log_prob": -15.507096295652445,
      "best_answer": "March 44 BC",
      "total_prob": 1.8422715630008965e-07,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 64,
      "generated_answer": "Harper Simon",
      "gold_answers": [
        "Harper Simon"
      ],
      "reference_answer": "Harper Simon",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Harper Simon": 0.9214998206872564
      },
      "individual_log_probs": {
        "Harper Simon": -0.08175269646017114
      },
      "max_prob": 0.9214998206872564,
      "max_log_prob": -0.08175269646017114,
      "best_answer": "Harper Simon",
      "total_prob": 0.9214998206872564,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 65,
      "generated_answer": "13 years",
      "gold_answers": [
        "six months"
      ],
      "reference_answer": "six months",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "six months": 1.1863086850601135e-05
      },
      "individual_log_probs": {
        "six months": -11.342078924179077
      },
      "max_prob": 1.1863086850601135e-05,
      "max_log_prob": -11.342078924179077,
      "best_answer": "six months",
      "total_prob": 1.1863086850601135e-05,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 66,
      "generated_answer": "James McCartney",
      "gold_answers": [
        "James McCartney"
      ],
      "reference_answer": "James McCartney",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "James McCartney": 0.5651647551023252
      },
      "individual_log_probs": {
        "James McCartney": -0.5706379883922637
      },
      "max_prob": 0.5651647551023252,
      "max_log_prob": -0.5706379883922637,
      "best_answer": "James McCartney",
      "total_prob": 0.5651647551023252,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 67,
      "generated_answer": "808",
      "gold_answers": [
        "808"
      ],
      "reference_answer": "808",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "808": 0.9765191403925474
      },
      "individual_log_probs": {
        "808": -0.023760927841067314
      },
      "max_prob": 0.9765191403925474,
      "max_log_prob": -0.023760927841067314,
      "best_answer": "808",
      "total_prob": 0.9765191403925474,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 68,
      "generated_answer": "Renault",
      "gold_answers": [
        "Louis Renault"
      ],
      "reference_answer": "Louis Renault",
      "em_score": 0.0,
      "f1_score": 0.6666666666666666,
      "precision": 1.0,
      "recall": 0.5,
      "individual_probs": {
        "Louis Renault": 1.494582186438778e-06
      },
      "individual_log_probs": {
        "Louis Renault": -13.413663864135742
      },
      "max_prob": 1.494582186438778e-06,
      "max_log_prob": -13.413663864135742,
      "best_answer": "Louis Renault",
      "total_prob": 1.494582186438778e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 69,
      "generated_answer": "UTF-16",
      "gold_answers": [
        "WGL-4 with 652 characters"
      ],
      "reference_answer": "WGL-4 with 652 characters",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "WGL-4 with 652 characters": 0.0045742662433945576
      },
      "individual_log_probs": {
        "WGL-4 with 652 characters": -5.387308977075008
      },
      "max_prob": 0.0045742662433945576,
      "max_log_prob": -5.387308977075008,
      "best_answer": "WGL-4 with 652 characters",
      "total_prob": 0.0045742662433945576,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 70,
      "generated_answer": "Pakatan Harapan",
      "gold_answers": [
        "Pakatan Harapan"
      ],
      "reference_answer": "Pakatan Harapan",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Pakatan Harapan": 0.9997955867148111
      },
      "individual_log_probs": {
        "Pakatan Harapan": -0.00020443418043214479
      },
      "max_prob": 0.9997955867148111,
      "max_log_prob": -0.00020443418043214479,
      "best_answer": "Pakatan Harapan",
      "total_prob": 0.9997955867148111,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 71,
      "generated_answer": "Speaker of the Lok Sabha",
      "gold_answers": [
        "Parliament of India"
      ],
      "reference_answer": "Parliament of India",
      "em_score": 0.0,
      "f1_score": 0.28571428571428575,
      "precision": 0.25,
      "recall": 0.3333333333333333,
      "individual_probs": {
        "Parliament of India": 1.9228924831125913e-07
      },
      "individual_log_probs": {
        "Parliament of India": -15.46426509693265
      },
      "max_prob": 1.9228924831125913e-07,
      "max_log_prob": -15.46426509693265,
      "best_answer": "Parliament of India",
      "total_prob": 1.9228924831125913e-07,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 72,
      "generated_answer": "Harvard University",
      "gold_answers": [
        "Harvard"
      ],
      "reference_answer": "Harvard",
      "em_score": 0.0,
      "f1_score": 0.6666666666666666,
      "precision": 0.5,
      "recall": 1.0,
      "individual_probs": {
        "Harvard": 0.9904133439780767
      },
      "individual_log_probs": {
        "Harvard": -0.009632903820602223
      },
      "max_prob": 0.9904133439780767,
      "max_log_prob": -0.009632903820602223,
      "best_answer": "Harvard",
      "total_prob": 0.9904133439780767,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 73,
      "generated_answer": "1. Chicago Cubs reason for poor late-season play unusually high number of day games.",
      "gold_answers": [
        "unusually high number of day games",
        "d",
        "day",
        "Day",
        "days"
      ],
      "reference_answer": "unusually high number of day games",
      "em_score": 0.0,
      "f1_score": 0.6,
      "precision": 0.42857142857142855,
      "recall": 1.0,
      "individual_probs": {
        "unusually high number of day games": 0.00019922357437946863,
        "d": 0.00018196811525379066,
        "day": 0.03926274359384406,
        "Day": 0.12260116182297387,
        "days": 3.116389742282985e-05
      },
      "individual_log_probs": {
        "unusually high number of day games": -8.52108287453757,
        "d": -8.611679077148438,
        "day": -3.2374792098999023,
        "Day": -2.098818778991699,
        "days": -10.376250267028809
      },
      "max_prob": 0.12260116182297387,
      "max_log_prob": -2.098818778991699,
      "best_answer": "Day",
      "total_prob": 0.16227626100387402,
      "answer_count": 5,
      "valid_answer_count": 5,
      "weight_w": 0.1
    },
    {
      "sample_idx": 74,
      "generated_answer": "month-long",
      "gold_answers": [
        "a month",
        "Month",
        "month"
      ],
      "reference_answer": "a month",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "a month": 0.008384104259163536,
        "Month": 0.022428273651206056,
        "month": 0.9162882587923674
      },
      "individual_log_probs": {
        "a month": -4.781417715988937,
        "Month": -3.7974328994750977,
        "month": -0.08742427080869675
      },
      "max_prob": 0.9162882587923674,
      "max_log_prob": -0.08742427080869675,
      "best_answer": "month",
      "total_prob": 0.947100636702737,
      "answer_count": 3,
      "valid_answer_count": 3,
      "weight_w": 0.1
    },
    {
      "sample_idx": 75,
      "generated_answer": "No.",
      "gold_answers": [
        "totals remain relatively small in relation to the total U.S population.",
        "the US",
        "America",
        "U.S.",
        "the United States",
        "United States",
        "US"
      ],
      "reference_answer": "totals remain relatively small in relation to the total U.S population.",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "totals remain relatively small in relation to the total U.S population.": 4.157394201677722e-30,
        "the US": 5.79860945400065e-09,
        "America": 2.9897046330086183e-06,
        "U.S.": 3.380453885002727e-06,
        "the United States": 1.076069485335375e-07,
        "United States": 2.1504396934524393e-06,
        "US": 1.7377167841213743e-06
      },
      "individual_log_probs": {
        "totals remain relatively small in relation to the total U.S population.": -67.65266430564225,
        "the US": -18.96564769744873,
        "America": -12.720335960388184,
        "U.S.": -12.597500571981072,
        "the United States": -16.044780613854527,
        "United States": -13.049838228151202,
        "US": -13.262938499450684
      },
      "max_prob": 3.380453885002727e-06,
      "max_log_prob": -12.597500571981072,
      "best_answer": "U.S.",
      "total_prob": 1.0371720553572698e-05,
      "answer_count": 7,
      "valid_answer_count": 7,
      "weight_w": 0.1
    },
    {
      "sample_idx": 76,
      "generated_answer": "1998",
      "gold_answers": [
        "1998"
      ],
      "reference_answer": "1998",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1998": 0.996392695194533
      },
      "individual_log_probs": {
        "1998": -0.0036138268187642097
      },
      "max_prob": 0.996392695194533,
      "max_log_prob": -0.0036138268187642097,
      "best_answer": "1998",
      "total_prob": 0.996392695194533,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 77,
      "generated_answer": "Veterans Stadium",
      "gold_answers": [
        "Lincoln Financial Field"
      ],
      "reference_answer": "Lincoln Financial Field",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Lincoln Financial Field": 0.2778014851124375
      },
      "individual_log_probs": {
        "Lincoln Financial Field": -1.2808485026990866
      },
      "max_prob": 0.2778014851124375,
      "max_log_prob": -1.2808485026990866,
      "best_answer": "Lincoln Financial Field",
      "total_prob": 0.2778014851124375,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 78,
      "generated_answer": "Aldemaro Romero",
      "gold_answers": [
        "Aldemaro Romero"
      ],
      "reference_answer": "Aldemaro Romero",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Aldemaro Romero": 0.9954888338639974
      },
      "individual_log_probs": {
        "Aldemaro Romero": -0.004521372151543801
      },
      "max_prob": 0.9954888338639974,
      "max_log_prob": -0.004521372151543801,
      "best_answer": "Aldemaro Romero",
      "total_prob": 0.9954888338639974,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 79,
      "generated_answer": "Rafina",
      "gold_answers": [
        "Amna Ilyas"
      ],
      "reference_answer": "Amna Ilyas",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Amna Ilyas": 2.5999572905657785e-07
      },
      "individual_log_probs": {
        "Amna Ilyas": -15.162600632771273
      },
      "max_prob": 2.5999572905657785e-07,
      "max_log_prob": -15.162600632771273,
      "best_answer": "Amna Ilyas",
      "total_prob": 2.5999572905657785e-07,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 80,
      "generated_answer": "Western Europe",
      "gold_answers": [
        "off the north - western coast of the European mainland"
      ],
      "reference_answer": "off the north - western coast of the European mainland",
      "em_score": 0.0,
      "f1_score": 0.22222222222222224,
      "precision": 0.5,
      "recall": 0.14285714285714285,
      "individual_probs": {
        "off the north - western coast of the European mainland": 3.7033166639847124e-18
      },
      "individual_log_probs": {
        "off the north - western coast of the European mainland": -40.13730286009377
      },
      "max_prob": 3.7033166639847124e-18,
      "max_log_prob": -40.13730286009377,
      "best_answer": "off the north - western coast of the European mainland",
      "total_prob": 3.7033166639847124e-18,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 81,
      "generated_answer": "Puerto Rico",
      "gold_answers": [
        "a key part of the Spanish Empire"
      ],
      "reference_answer": "a key part of the Spanish Empire",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "a key part of the Spanish Empire": 6.742982136234005e-13
      },
      "individual_log_probs": {
        "a key part of the Spanish Empire": -28.02510392840486
      },
      "max_prob": 6.742982136234005e-13,
      "max_log_prob": -28.02510392840486,
      "best_answer": "a key part of the Spanish Empire",
      "total_prob": 6.742982136234005e-13,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 82,
      "generated_answer": "Nonpoint is not mentioned in the given context.",
      "gold_answers": [
        "165,521"
      ],
      "reference_answer": "165,521",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "165,521": 1.8494572631551164e-09
      },
      "individual_log_probs": {
        "165,521": -20.10837361216545
      },
      "max_prob": 1.8494572631551164e-09,
      "max_log_prob": -20.10837361216545,
      "best_answer": "165,521",
      "total_prob": 1.8494572631551164e-09,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 83,
      "generated_answer": "Sudhir Mungantiwar",
      "gold_answers": [
        "Sudhir Mungantiwar"
      ],
      "reference_answer": "Sudhir Mungantiwar",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Sudhir Mungantiwar": 0.9992229035657456
      },
      "individual_log_probs": {
        "Sudhir Mungantiwar": -0.0007773985302037545
      },
      "max_prob": 0.9992229035657456,
      "max_log_prob": -0.0007773985302037545,
      "best_answer": "Sudhir Mungantiwar",
      "total_prob": 0.9992229035657456,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 84,
      "generated_answer": "Blue Nile",
      "gold_answers": [
        "Blue Nile"
      ],
      "reference_answer": "Blue Nile",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Blue Nile": 0.494468231541598
      },
      "individual_log_probs": {
        "Blue Nile": -0.7042723735794425
      },
      "max_prob": 0.494468231541598,
      "max_log_prob": -0.7042723735794425,
      "best_answer": "Blue Nile",
      "total_prob": 0.494468231541598,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 85,
      "generated_answer": "Steve Jobs",
      "gold_answers": [
        "Steve Jobs"
      ],
      "reference_answer": "Steve Jobs",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Steve Jobs": 0.9996134100212511
      },
      "individual_log_probs": {
        "Steve Jobs": -0.0003866647239192389
      },
      "max_prob": 0.9996134100212511,
      "max_log_prob": -0.0003866647239192389,
      "best_answer": "Steve Jobs",
      "total_prob": 0.9996134100212511,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 86,
      "generated_answer": "Elliot Handler",
      "gold_answers": [
        "Elliot Handler"
      ],
      "reference_answer": "Elliot Handler",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Elliot Handler": 0.7907961910603456
      },
      "individual_log_probs": {
        "Elliot Handler": -0.23471500426234115
      },
      "max_prob": 0.7907961910603456,
      "max_log_prob": -0.23471500426234115,
      "best_answer": "Elliot Handler",
      "total_prob": 0.7907961910603456,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 87,
      "generated_answer": "49",
      "gold_answers": [
        "49"
      ],
      "reference_answer": "49",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "49": 0.9996192713421876
      },
      "individual_log_probs": {
        "49": -0.0003808011533692479
      },
      "max_prob": 0.9996192713421876,
      "max_log_prob": -0.0003808011533692479,
      "best_answer": "49",
      "total_prob": 0.9996192713421876,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 88,
      "generated_answer": "Bill Clinton",
      "gold_answers": [
        "Arkansas Attorney General"
      ],
      "reference_answer": "Arkansas Attorney General",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Arkansas Attorney General": 4.321954862212197e-11
      },
      "individual_log_probs": {
        "Arkansas Attorney General": -23.864728208631277
      },
      "max_prob": 4.321954862212197e-11,
      "max_log_prob": -23.864728208631277,
      "best_answer": "Arkansas Attorney General",
      "total_prob": 4.321954862212197e-11,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 89,
      "generated_answer": "Antoine Marchand",
      "gold_answers": [
        "RCA Records",
        "RCA"
      ],
      "reference_answer": "RCA Records",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "RCA Records": 0.18041898359325895,
        "RCA": 0.21442433715462617
      },
      "individual_log_probs": {
        "RCA Records": -1.7124734463286586,
        "RCA": -1.5397983433795162
      },
      "max_prob": 0.21442433715462617,
      "max_log_prob": -1.5397983433795162,
      "best_answer": "RCA",
      "total_prob": 0.3948433207478851,
      "answer_count": 2,
      "valid_answer_count": 2,
      "weight_w": 0.1
    },
    {
      "sample_idx": 90,
      "generated_answer": "Kapan",
      "gold_answers": [
        "Kapan"
      ],
      "reference_answer": "Kapan",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Kapan": 0.9931614850985826
      },
      "individual_log_probs": {
        "Kapan": -0.006862004695904034
      },
      "max_prob": 0.9931614850985826,
      "max_log_prob": -0.006862004695904034,
      "best_answer": "Kapan",
      "total_prob": 0.9931614850985826,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 91,
      "generated_answer": "Trajan",
      "gold_answers": [
        "Marcia"
      ],
      "reference_answer": "Marcia",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Marcia": 0.002116629372845252
      },
      "individual_log_probs": {
        "Marcia": -6.1579303740290925
      },
      "max_prob": 0.002116629372845252,
      "max_log_prob": -6.1579303740290925,
      "best_answer": "Marcia",
      "total_prob": 0.002116629372845252,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 92,
      "generated_answer": "National Rail Museum",
      "gold_answers": [
        "National Rail Museum"
      ],
      "reference_answer": "National Rail Museum",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "National Rail Museum": 0.9924095031529381
      },
      "individual_log_probs": {
        "National Rail Museum": -0.007619451280334033
      },
      "max_prob": 0.9924095031529381,
      "max_log_prob": -0.007619451280334033,
      "best_answer": "National Rail Museum",
      "total_prob": 0.9924095031529381,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 93,
      "generated_answer": "The Near East.",
      "gold_answers": [
        "\"the East Indies\"",
        "East Indies"
      ],
      "reference_answer": "\"the East Indies\"",
      "em_score": 0.0,
      "f1_score": 0.5,
      "precision": 0.5,
      "recall": 0.5,
      "individual_probs": {
        "\"the East Indies\"": 1.958924570381006e-08,
        "East Indies": 1.4674374269155665e-05
      },
      "individual_log_probs": {
        "\"the East Indies\"": -17.748285109875724,
        "East Indies": -11.12940783239901
      },
      "max_prob": 1.4674374269155665e-05,
      "max_log_prob": -11.12940783239901,
      "best_answer": "East Indies",
      "total_prob": 1.4693963514859474e-05,
      "answer_count": 2,
      "valid_answer_count": 2,
      "weight_w": 0.1
    },
    {
      "sample_idx": 94,
      "generated_answer": "There is no university founded by George Low. George Low was the 14th President of Rensselaer Polytechn",
      "gold_answers": [
        "1824"
      ],
      "reference_answer": "1824",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1824": 0.001254581905544727
      },
      "individual_log_probs": {
        "1824": -6.6809529048950935
      },
      "max_prob": 0.001254581905544727,
      "max_log_prob": -6.6809529048950935,
      "best_answer": "1824",
      "total_prob": 0.001254581905544727,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 95,
      "generated_answer": "Nintendo",
      "gold_answers": [
        "first-party games"
      ],
      "reference_answer": "first-party games",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "first-party games": 2.43499937192306e-10
      },
      "individual_log_probs": {
        "first-party games": -22.13590443134308
      },
      "max_prob": 2.43499937192306e-10,
      "max_log_prob": -22.13590443134308,
      "best_answer": "first-party games",
      "total_prob": 2.43499937192306e-10,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 96,
      "generated_answer": "United States",
      "gold_answers": [
        "United States",
        "US of A",
        "U.S.",
        "US",
        "U.S"
      ],
      "reference_answer": "United States",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "United States": 0.870203677334472,
        "US of A": 6.851139126443272e-13,
        "U.S.": 3.5463689877928887e-07,
        "US": 5.739594985755303e-06,
        "U.S": 2.0890687100081326e-06
      },
      "individual_log_probs": {
        "United States": -0.13902798285471363,
        "US of A": -28.009191274642944,
        "U.S.": -14.852171391248703,
        "US": -12.068121910095215,
        "U.S": -13.078792184591293
      },
      "max_prob": 0.870203677334472,
      "max_log_prob": -0.13902798285471363,
      "best_answer": "United States",
      "total_prob": 0.8702118606357516,
      "answer_count": 5,
      "valid_answer_count": 5,
      "weight_w": 0.1
    },
    {
      "sample_idx": 97,
      "generated_answer": "Alberto Savinio.",
      "gold_answers": [
        "Alberto Savinio"
      ],
      "reference_answer": "Alberto Savinio",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Alberto Savinio": 0.8741207888536896
      },
      "individual_log_probs": {
        "Alberto Savinio": -0.1345367105259072
      },
      "max_prob": 0.8741207888536896,
      "max_log_prob": -0.1345367105259072,
      "best_answer": "Alberto Savinio",
      "total_prob": 0.8741207888536896,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 98,
      "generated_answer": "Seth Magaziner, Rhode Island",
      "gold_answers": [
        "Seth Magaziner"
      ],
      "reference_answer": "Seth Magaziner",
      "em_score": 0.0,
      "f1_score": 0.6666666666666666,
      "precision": 0.5,
      "recall": 1.0,
      "individual_probs": {
        "Seth Magaziner": 0.9623697383772978
      },
      "individual_log_probs": {
        "Seth Magaziner": -0.038356558729901735
      },
      "max_prob": 0.9623697383772978,
      "max_log_prob": -0.038356558729901735,
      "best_answer": "Seth Magaziner",
      "total_prob": 0.9623697383772978,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    },
    {
      "sample_idx": 99,
      "generated_answer": "Nanjing",
      "gold_answers": [
        "Qiantang"
      ],
      "reference_answer": "Qiantang",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Qiantang": 4.509605966146447e-08
      },
      "individual_log_probs": {
        "Qiantang": -16.914470963180065
      },
      "max_prob": 4.509605966146447e-08,
      "max_log_prob": -16.914470963180065,
      "best_answer": "Qiantang",
      "total_prob": 4.509605966146447e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.1
    }
  ]
}