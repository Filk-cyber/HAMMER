{
  "metrics": {
    "weight_w": 0.5,
    "input_file": "/home/jiangjp/trace-idea/data/hotpotqa/hotpotqa_dev100ideal_with_reasoning_chains_modify_w05.json",
    "total_samples": 100,
    "exact_match": 0.72,
    "f1": 0.7754523809523809,
    "precision": 0.780595238095238,
    "recall": 0.7933333333333333,
    "avg_max_log_prob": -3.915191262991586,
    "avg_max_prob": 0.5958129873392743,
    "avg_total_prob": 0.5958129873392743,
    "valid_max_prob_samples": 100,
    "invalid_max_prob_samples": 0,
    "avg_answer_count": 1.0,
    "avg_valid_answer_count": 1.0
  },
  "sample_info": [
    {
      "sample_idx": 0,
      "generated_answer": "No.",
      "gold_answers": [
        "no"
      ],
      "reference_answer": "no",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "no": 0.001522500111046749
      },
      "individual_log_probs": {
        "no": -6.487401485443115
      },
      "max_prob": 0.001522500111046749,
      "max_log_prob": -6.487401485443115,
      "best_answer": "no",
      "total_prob": 0.001522500111046749,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 1,
      "generated_answer": "University of Delaware",
      "gold_answers": [
        "University of Delaware"
      ],
      "reference_answer": "University of Delaware",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "University of Delaware": 0.649020116036572
      },
      "individual_log_probs": {
        "University of Delaware": -0.43229156732454044
      },
      "max_prob": 0.649020116036572,
      "max_log_prob": -0.43229156732454044,
      "best_answer": "University of Delaware",
      "total_prob": 0.649020116036572,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 2,
      "generated_answer": "February 26, 2009",
      "gold_answers": [
        "NBC"
      ],
      "reference_answer": "NBC",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "NBC": 0.004320473410630804
      },
      "individual_log_probs": {
        "NBC": -5.444390296936035
      },
      "max_prob": 0.004320473410630804,
      "max_log_prob": -5.444390296936035,
      "best_answer": "NBC",
      "total_prob": 0.004320473410630804,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 3,
      "generated_answer": "Monocotyledonous",
      "gold_answers": [
        "genus"
      ],
      "reference_answer": "genus",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "genus": 0.009313698045099562
      },
      "individual_log_probs": {
        "genus": -4.676269054412842
      },
      "max_prob": 0.009313698045099562,
      "max_log_prob": -4.676269054412842,
      "best_answer": "genus",
      "total_prob": 0.009313698045099562,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 4,
      "generated_answer": "Kirk Fogg.",
      "gold_answers": [
        "Jeff Sutphen"
      ],
      "reference_answer": "Jeff Sutphen",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Jeff Sutphen": 0.16783009481206052
      },
      "individual_log_probs": {
        "Jeff Sutphen": -1.7848031517330512
      },
      "max_prob": 0.16783009481206052,
      "max_log_prob": -1.7848031517330512,
      "best_answer": "Jeff Sutphen",
      "total_prob": 0.16783009481206052,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 5,
      "generated_answer": "Bowland Fells",
      "gold_answers": [
        "the Bowland Fells"
      ],
      "reference_answer": "the Bowland Fells",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "the Bowland Fells": 9.851836695816895e-06
      },
      "individual_log_probs": {
        "the Bowland Fells": -11.527852653582613
      },
      "max_prob": 9.851836695816895e-06,
      "max_log_prob": -11.527852653582613,
      "best_answer": "the Bowland Fells",
      "total_prob": 9.851836695816895e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 6,
      "generated_answer": "Daft Punk",
      "gold_answers": [
        "Daft Punk"
      ],
      "reference_answer": "Daft Punk",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Daft Punk": 0.9994733668169911
      },
      "individual_log_probs": {
        "Daft Punk": -0.0005267719029689033
      },
      "max_prob": 0.9994733668169911,
      "max_log_prob": -0.0005267719029689033,
      "best_answer": "Daft Punk",
      "total_prob": 0.9994733668169911,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 7,
      "generated_answer": "3rd Rock from the Sun",
      "gold_answers": [
        "3rd Rock from the Sun"
      ],
      "reference_answer": "3rd Rock from the Sun",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "3rd Rock from the Sun": 0.9791567847106767
      },
      "individual_log_probs": {
        "3rd Rock from the Sun": -0.021063501459131828
      },
      "max_prob": 0.9791567847106767,
      "max_log_prob": -0.021063501459131828,
      "best_answer": "3rd Rock from the Sun",
      "total_prob": 0.9791567847106767,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 8,
      "generated_answer": "The Island (2005 film)",
      "gold_answers": [
        "The Island"
      ],
      "reference_answer": "The Island",
      "em_score": 0.0,
      "f1_score": 0.5,
      "precision": 0.3333333333333333,
      "recall": 1.0,
      "individual_probs": {
        "The Island": 0.5183551636180861
      },
      "individual_log_probs": {
        "The Island": -0.6570946276187897
      },
      "max_prob": 0.5183551636180861,
      "max_log_prob": -0.6570946276187897,
      "best_answer": "The Island",
      "total_prob": 0.5183551636180861,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 9,
      "generated_answer": "The Great Mouse Detective",
      "gold_answers": [
        "The Great Mouse Detective"
      ],
      "reference_answer": "The Great Mouse Detective",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "The Great Mouse Detective": 0.9499930859649492
      },
      "individual_log_probs": {
        "The Great Mouse Detective": -0.051300572345667206
      },
      "max_prob": 0.9499930859649492,
      "max_log_prob": -0.051300572345667206,
      "best_answer": "The Great Mouse Detective",
      "total_prob": 0.9499930859649492,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 10,
      "generated_answer": "2003",
      "gold_answers": [
        "20 March to 1 May 2003"
      ],
      "reference_answer": "20 March to 1 May 2003",
      "em_score": 0.0,
      "f1_score": 0.2857142857142857,
      "precision": 1.0,
      "recall": 0.16666666666666666,
      "individual_probs": {
        "20 March to 1 May 2003": 0.07332542407300008
      },
      "individual_log_probs": {
        "20 March to 1 May 2003": -2.6128478806644964
      },
      "max_prob": 0.07332542407300008,
      "max_log_prob": -2.6128478806644964,
      "best_answer": "20 March to 1 May 2003",
      "total_prob": 0.07332542407300008,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 11,
      "generated_answer": "A genus of flowering plant.",
      "gold_answers": [
        "plant"
      ],
      "reference_answer": "plant",
      "em_score": 0.0,
      "f1_score": 0.4,
      "precision": 0.25,
      "recall": 1.0,
      "individual_probs": {
        "plant": 0.00019008487137297373
      },
      "individual_log_probs": {
        "plant": -8.568039894104004
      },
      "max_prob": 0.00019008487137297373,
      "max_log_prob": -8.568039894104004,
      "best_answer": "plant",
      "total_prob": 0.00019008487137297373,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 12,
      "generated_answer": "Montclair State University",
      "gold_answers": [
        "Montclair State University"
      ],
      "reference_answer": "Montclair State University",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Montclair State University": 0.9990029842647452
      },
      "individual_log_probs": {
        "Montclair State University": -0.0009975130860482295
      },
      "max_prob": 0.9990029842647452,
      "max_log_prob": -0.0009975130860482295,
      "best_answer": "Montclair State University",
      "total_prob": 0.9990029842647452,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 13,
      "generated_answer": "Soha Ali Khan",
      "gold_answers": [
        "Soha Ali Khan"
      ],
      "reference_answer": "Soha Ali Khan",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Soha Ali Khan": 0.9997386327121937
      },
      "individual_log_probs": {
        "Soha Ali Khan": -0.0002614014501887141
      },
      "max_prob": 0.9997386327121937,
      "max_log_prob": -0.0002614014501887141,
      "best_answer": "Soha Ali Khan",
      "total_prob": 0.9997386327121937,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 14,
      "generated_answer": "Yes",
      "gold_answers": [
        "yes"
      ],
      "reference_answer": "yes",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "yes": 0.0010491944204772015
      },
      "individual_log_probs": {
        "yes": -6.859732627868652
      },
      "max_prob": 0.0010491944204772015,
      "max_log_prob": -6.859732627868652,
      "best_answer": "yes",
      "total_prob": 0.0010491944204772015,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 15,
      "generated_answer": "Bodo League massacre.",
      "gold_answers": [
        "Bodo League massacre"
      ],
      "reference_answer": "Bodo League massacre",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Bodo League massacre": 0.9762675510342503
      },
      "individual_log_probs": {
        "Bodo League massacre": -0.024018599977807753
      },
      "max_prob": 0.9762675510342503,
      "max_log_prob": -0.024018599977807753,
      "best_answer": "Bodo League massacre",
      "total_prob": 0.9762675510342503,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 16,
      "generated_answer": "Ariocarpus",
      "gold_answers": [
        "Ariocarpus"
      ],
      "reference_answer": "Ariocarpus",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Ariocarpus": 0.9972108824441801
      },
      "individual_log_probs": {
        "Ariocarpus": -0.002793014391698989
      },
      "max_prob": 0.9972108824441801,
      "max_log_prob": -0.002793014391698989,
      "best_answer": "Ariocarpus",
      "total_prob": 0.9972108824441801,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 17,
      "generated_answer": "761",
      "gold_answers": [
        "761"
      ],
      "reference_answer": "761",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "761": 0.9916557065128049
      },
      "individual_log_probs": {
        "761": -0.008379301987588406
      },
      "max_prob": 0.9916557065128049,
      "max_log_prob": -0.008379301987588406,
      "best_answer": "761",
      "total_prob": 0.9916557065128049,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 18,
      "generated_answer": "Cnut the Great",
      "gold_answers": [
        "Cnut the Great"
      ],
      "reference_answer": "Cnut the Great",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Cnut the Great": 0.9675433540540973
      },
      "individual_log_probs": {
        "Cnut the Great": -0.032995044690323994
      },
      "max_prob": 0.9675433540540973,
      "max_log_prob": -0.032995044690323994,
      "best_answer": "Cnut the Great",
      "total_prob": 0.9675433540540973,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 19,
      "generated_answer": "Channel V",
      "gold_answers": [
        "Channel V"
      ],
      "reference_answer": "Channel V",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Channel V": 0.999188366385839
      },
      "individual_log_probs": {
        "Channel V": -0.0008119631670524541
      },
      "max_prob": 0.999188366385839,
      "max_log_prob": -0.0008119631670524541,
      "best_answer": "Channel V",
      "total_prob": 0.999188366385839,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 20,
      "generated_answer": "Albert Camus",
      "gold_answers": [
        "Albert Camus"
      ],
      "reference_answer": "Albert Camus",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Albert Camus": 0.998095771803141
      },
      "individual_log_probs": {
        "Albert Camus": -0.001906043544295244
      },
      "max_prob": 0.998095771803141,
      "max_log_prob": -0.001906043544295244,
      "best_answer": "Albert Camus",
      "total_prob": 0.998095771803141,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 21,
      "generated_answer": "Paul Marcinkus",
      "gold_answers": [
        "Paul Marcinkus"
      ],
      "reference_answer": "Paul Marcinkus",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Paul Marcinkus": 0.997853486847356
      },
      "individual_log_probs": {
        "Paul Marcinkus": -0.0021488202140176327
      },
      "max_prob": 0.997853486847356,
      "max_log_prob": -0.0021488202140176327,
      "best_answer": "Paul Marcinkus",
      "total_prob": 0.997853486847356,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 22,
      "generated_answer": "1852",
      "gold_answers": [
        "1904"
      ],
      "reference_answer": "1904",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1904": 2.1251451941856104e-10
      },
      "individual_log_probs": {
        "1904": -22.272010803222656
      },
      "max_prob": 2.1251451941856104e-10,
      "max_log_prob": -22.272010803222656,
      "best_answer": "1904",
      "total_prob": 2.1251451941856104e-10,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 23,
      "generated_answer": "Ralph Fiennes",
      "gold_answers": [
        "Ralph Fiennes"
      ],
      "reference_answer": "Ralph Fiennes",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Ralph Fiennes": 0.9998426609826714
      },
      "individual_log_probs": {
        "Ralph Fiennes": -0.00015735139641037676
      },
      "max_prob": 0.9998426609826714,
      "max_log_prob": -0.00015735139641037676,
      "best_answer": "Ralph Fiennes",
      "total_prob": 0.9998426609826714,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 24,
      "generated_answer": "runner-up in the Bundesliga to SV Werder Bremen",
      "gold_answers": [
        "runner-up"
      ],
      "reference_answer": "runner-up",
      "em_score": 0.0,
      "f1_score": 0.25,
      "precision": 0.14285714285714285,
      "recall": 1.0,
      "individual_probs": {
        "runner-up": 0.8374212231990406
      },
      "individual_log_probs": {
        "runner-up": -0.17742808155890089
      },
      "max_prob": 0.8374212231990406,
      "max_log_prob": -0.17742808155890089,
      "best_answer": "runner-up",
      "total_prob": 0.8374212231990406,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 25,
      "generated_answer": "Swedish",
      "gold_answers": [
        "Swedish"
      ],
      "reference_answer": "Swedish",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Swedish": 0.998579971018977
      },
      "individual_log_probs": {
        "Swedish": -0.0014210381776820213
      },
      "max_prob": 0.998579971018977,
      "max_log_prob": -0.0014210381776820213,
      "best_answer": "Swedish",
      "total_prob": 0.998579971018977,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 26,
      "generated_answer": "Vice",
      "gold_answers": [
        "Vice"
      ],
      "reference_answer": "Vice",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Vice": 0.9913604556033929
      },
      "individual_log_probs": {
        "Vice": -0.008677081619680393
      },
      "max_prob": 0.9913604556033929,
      "max_log_prob": -0.008677081619680393,
      "best_answer": "Vice",
      "total_prob": 0.9913604556033929,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 27,
      "generated_answer": "The Preppie Murder",
      "gold_answers": [
        "The Preppie Murder"
      ],
      "reference_answer": "The Preppie Murder",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "The Preppie Murder": 0.9589104360885522
      },
      "individual_log_probs": {
        "The Preppie Murder": -0.04195760148559202
      },
      "max_prob": 0.9589104360885522,
      "max_log_prob": -0.04195760148559202,
      "best_answer": "The Preppie Murder",
      "total_prob": 0.9589104360885522,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 28,
      "generated_answer": "Isolde Kostner",
      "gold_answers": [
        "Isolde Kostner"
      ],
      "reference_answer": "Isolde Kostner",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Isolde Kostner": 0.9319438306105224
      },
      "individual_log_probs": {
        "Isolde Kostner": -0.07048273369798608
      },
      "max_prob": 0.9319438306105224,
      "max_log_prob": -0.07048273369798608,
      "best_answer": "Isolde Kostner",
      "total_prob": 0.9319438306105224,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 29,
      "generated_answer": "Westwood Jr. High School",
      "gold_answers": [
        "Beverly Hills High School"
      ],
      "reference_answer": "Beverly Hills High School",
      "em_score": 0.0,
      "f1_score": 0.5,
      "precision": 0.5,
      "recall": 0.5,
      "individual_probs": {
        "Beverly Hills High School": 8.387640244552502e-07
      },
      "individual_log_probs": {
        "Beverly Hills High School": -13.991336428138311
      },
      "max_prob": 8.387640244552502e-07,
      "max_log_prob": -13.991336428138311,
      "best_answer": "Beverly Hills High School",
      "total_prob": 8.387640244552502e-07,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 30,
      "generated_answer": "1989",
      "gold_answers": [
        "fifth album"
      ],
      "reference_answer": "fifth album",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "fifth album": 1.803529623256158e-11
      },
      "individual_log_probs": {
        "fifth album": -24.73869037628174
      },
      "max_prob": 1.803529623256158e-11,
      "max_log_prob": -24.73869037628174,
      "best_answer": "fifth album",
      "total_prob": 1.803529623256158e-11,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 31,
      "generated_answer": "Welterweight",
      "gold_answers": [
        "Welterweight"
      ],
      "reference_answer": "Welterweight",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Welterweight": 0.9957659202367456
      },
      "individual_log_probs": {
        "Welterweight": -0.0042430688616548196
      },
      "max_prob": 0.9957659202367456,
      "max_log_prob": -0.0042430688616548196,
      "best_answer": "Welterweight",
      "total_prob": 0.9957659202367456,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 32,
      "generated_answer": "Times Beach",
      "gold_answers": [
        "Times Beach"
      ],
      "reference_answer": "Times Beach",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Times Beach": 0.9994786084522431
      },
      "individual_log_probs": {
        "Times Beach": -0.0005215275195951108
      },
      "max_prob": 0.9994786084522431,
      "max_log_prob": -0.0005215275195951108,
      "best_answer": "Times Beach",
      "total_prob": 0.9994786084522431,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 33,
      "generated_answer": "Beverly Hills Supper Club fire.",
      "gold_answers": [
        "Beverly Hills Supper Club fire"
      ],
      "reference_answer": "Beverly Hills Supper Club fire",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Beverly Hills Supper Club fire": 0.49361760164770274
      },
      "individual_log_probs": {
        "Beverly Hills Supper Club fire": -0.705994147286674
      },
      "max_prob": 0.49361760164770274,
      "max_log_prob": -0.705994147286674,
      "best_answer": "Beverly Hills Supper Club fire",
      "total_prob": 0.49361760164770274,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 34,
      "generated_answer": "Quarterback",
      "gold_answers": [
        "quarterback"
      ],
      "reference_answer": "quarterback",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "quarterback": 0.32395338027513926
      },
      "individual_log_probs": {
        "quarterback": -1.1271556615823783
      },
      "max_prob": 0.32395338027513926,
      "max_log_prob": -1.1271556615823783,
      "best_answer": "quarterback",
      "total_prob": 0.32395338027513926,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 35,
      "generated_answer": "Dusty Dvoracek",
      "gold_answers": [
        "Dusty Dvoracek"
      ],
      "reference_answer": "Dusty Dvoracek",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Dusty Dvoracek": 0.9994438567611816
      },
      "individual_log_probs": {
        "Dusty Dvoracek": -0.0005562979438309412
      },
      "max_prob": 0.9994438567611816,
      "max_log_prob": -0.0005562979438309412,
      "best_answer": "Dusty Dvoracek",
      "total_prob": 0.9994438567611816,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 36,
      "generated_answer": "No.",
      "gold_answers": [
        "no"
      ],
      "reference_answer": "no",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "no": 0.008203444117386037
      },
      "individual_log_probs": {
        "no": -4.803201198577881
      },
      "max_prob": 0.008203444117386037,
      "max_log_prob": -4.803201198577881,
      "best_answer": "no",
      "total_prob": 0.008203444117386037,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 37,
      "generated_answer": "Texas Rangers",
      "gold_answers": [
        "Texas Rangers"
      ],
      "reference_answer": "Texas Rangers",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Texas Rangers": 0.6423401834657594
      },
      "individual_log_probs": {
        "Texas Rangers": -0.44263723484164075
      },
      "max_prob": 0.6423401834657594,
      "max_log_prob": -0.44263723484164075,
      "best_answer": "Texas Rangers",
      "total_prob": 0.6423401834657594,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 38,
      "generated_answer": "Baltic, Germanic, and Thracian tribes.",
      "gold_answers": [
        "Germanic, Baltic and Thracian tribes"
      ],
      "reference_answer": "Germanic, Baltic and Thracian tribes",
      "em_score": 0.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Germanic, Baltic and Thracian tribes": 0.0001787727138776406
      },
      "individual_log_probs": {
        "Germanic, Baltic and Thracian tribes": -8.629395313818804
      },
      "max_prob": 0.0001787727138776406,
      "max_log_prob": -8.629395313818804,
      "best_answer": "Germanic, Baltic and Thracian tribes",
      "total_prob": 0.0001787727138776406,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 39,
      "generated_answer": "American",
      "gold_answers": [
        "American"
      ],
      "reference_answer": "American",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "American": 0.9994787312391036
      },
      "individual_log_probs": {
        "American": -0.0005214046686887741
      },
      "max_prob": 0.9994787312391036,
      "max_log_prob": -0.0005214046686887741,
      "best_answer": "American",
      "total_prob": 0.9994787312391036,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 40,
      "generated_answer": "Mario Lemieux",
      "gold_answers": [
        "Mario Lemieux"
      ],
      "reference_answer": "Mario Lemieux",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Mario Lemieux": 0.9998479100808073
      },
      "individual_log_probs": {
        "Mario Lemieux": -0.00015210148603728157
      },
      "max_prob": 0.9998479100808073,
      "max_log_prob": -0.00015210148603728157,
      "best_answer": "Mario Lemieux",
      "total_prob": 0.9998479100808073,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 41,
      "generated_answer": "Mumbai",
      "gold_answers": [
        "Mumbai"
      ],
      "reference_answer": "Mumbai",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Mumbai": 0.9990220042415504
      },
      "individual_log_probs": {
        "Mumbai": -0.0009784743083400826
      },
      "max_prob": 0.9990220042415504,
      "max_log_prob": -0.0009784743083400826,
      "best_answer": "Mumbai",
      "total_prob": 0.9990220042415504,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 42,
      "generated_answer": "Alexander Scriabin",
      "gold_answers": [
        "Alexander Scriabin"
      ],
      "reference_answer": "Alexander Scriabin",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Alexander Scriabin": 0.9811905970991852
      },
      "individual_log_probs": {
        "Alexander Scriabin": -0.018988549706108415
      },
      "max_prob": 0.9811905970991852,
      "max_log_prob": -0.018988549706108415,
      "best_answer": "Alexander Scriabin",
      "total_prob": 0.9811905970991852,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 43,
      "generated_answer": "4",
      "gold_answers": [
        "Their biggest hit was \"Tall Cool One\", first released in 1959"
      ],
      "reference_answer": "Their biggest hit was \"Tall Cool One\", first released in 1959",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Their biggest hit was \"Tall Cool One\", first released in 1959": 2.651450325422295e-16
      },
      "individual_log_probs": {
        "Their biggest hit was \"Tall Cool One\", first released in 1959": -35.866254705004394
      },
      "max_prob": 2.651450325422295e-16,
      "max_log_prob": -35.866254705004394,
      "best_answer": "Their biggest hit was \"Tall Cool One\", first released in 1959",
      "total_prob": 2.651450325422295e-16,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 44,
      "generated_answer": "Jawaharlal Nehru",
      "gold_answers": [
        "first Prime Minister of India"
      ],
      "reference_answer": "first Prime Minister of India",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "first Prime Minister of India": 0.0004469827644877505
      },
      "individual_log_probs": {
        "first Prime Minister of India": -7.712990522287043
      },
      "max_prob": 0.0004469827644877505,
      "max_log_prob": -7.712990522287043,
      "best_answer": "first Prime Minister of India",
      "total_prob": 0.0004469827644877505,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 45,
      "generated_answer": "Ireland",
      "gold_answers": [
        "Ireland"
      ],
      "reference_answer": "Ireland",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Ireland": 0.8071416673809481
      },
      "individual_log_probs": {
        "Ireland": -0.21425607793935342
      },
      "max_prob": 0.8071416673809481,
      "max_log_prob": -0.21425607793935342,
      "best_answer": "Ireland",
      "total_prob": 0.8071416673809481,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 46,
      "generated_answer": "72-78",
      "gold_answers": [
        "72-78"
      ],
      "reference_answer": "72-78",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "72-78": 0.9978268653477176
      },
      "individual_log_probs": {
        "72-78": -0.002175499335862696
      },
      "max_prob": 0.9978268653477176,
      "max_log_prob": -0.002175499335862696,
      "best_answer": "72-78",
      "total_prob": 0.9978268653477176,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 47,
      "generated_answer": "Heroica Matamoros",
      "gold_answers": [
        "Heroica Matamoros"
      ],
      "reference_answer": "Heroica Matamoros",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Heroica Matamoros": 0.9868493188793025
      },
      "individual_log_probs": {
        "Heroica Matamoros": -0.013237916979043973
      },
      "max_prob": 0.9868493188793025,
      "max_log_prob": -0.013237916979043973,
      "best_answer": "Heroica Matamoros",
      "total_prob": 0.9868493188793025,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 48,
      "generated_answer": "Benedict Arnold",
      "gold_answers": [
        "Benedict Arnold"
      ],
      "reference_answer": "Benedict Arnold",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Benedict Arnold": 0.9929825296968522
      },
      "individual_log_probs": {
        "Benedict Arnold": -0.007042208549080442
      },
      "max_prob": 0.9929825296968522,
      "max_log_prob": -0.007042208549080442,
      "best_answer": "Benedict Arnold",
      "total_prob": 0.9929825296968522,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 49,
      "generated_answer": "South Kesteven Sports Stadium",
      "gold_answers": [
        "South Kesteven Sports Stadium"
      ],
      "reference_answer": "South Kesteven Sports Stadium",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "South Kesteven Sports Stadium": 0.956191548727117
      },
      "individual_log_probs": {
        "South Kesteven Sports Stadium": -0.04479702122375784
      },
      "max_prob": 0.956191548727117,
      "max_log_prob": -0.04479702122375784,
      "best_answer": "South Kesteven Sports Stadium",
      "total_prob": 0.956191548727117,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 50,
      "generated_answer": "Aiko, Princess Toshi",
      "gold_answers": [
        "Aiko, Princess Toshi"
      ],
      "reference_answer": "Aiko, Princess Toshi",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Aiko, Princess Toshi": 0.7577231120344974
      },
      "individual_log_probs": {
        "Aiko, Princess Toshi": -0.2774372476269491
      },
      "max_prob": 0.7577231120344974,
      "max_log_prob": -0.2774372476269491,
      "best_answer": "Aiko, Princess Toshi",
      "total_prob": 0.7577231120344974,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 51,
      "generated_answer": "Naseem Hamed",
      "gold_answers": [
        "Marco Antonio Barrera"
      ],
      "reference_answer": "Marco Antonio Barrera",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Marco Antonio Barrera": 3.8820000428704656e-08
      },
      "individual_log_probs": {
        "Marco Antonio Barrera": -17.06433024816215
      },
      "max_prob": 3.8820000428704656e-08,
      "max_log_prob": -17.06433024816215,
      "best_answer": "Marco Antonio Barrera",
      "total_prob": 3.8820000428704656e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 52,
      "generated_answer": "Iberian Peninsula",
      "gold_answers": [
        "Iberian Peninsula"
      ],
      "reference_answer": "Iberian Peninsula",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Iberian Peninsula": 0.871982718098658
      },
      "individual_log_probs": {
        "Iberian Peninsula": -0.13698567396374983
      },
      "max_prob": 0.871982718098658,
      "max_log_prob": -0.13698567396374983,
      "best_answer": "Iberian Peninsula",
      "total_prob": 0.871982718098658,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 53,
      "generated_answer": "Hume Highway",
      "gold_answers": [
        "Hume Highway"
      ],
      "reference_answer": "Hume Highway",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Hume Highway": 0.7430273923019195
      },
      "individual_log_probs": {
        "Hume Highway": -0.29702236778121005
      },
      "max_prob": 0.7430273923019195,
      "max_log_prob": -0.29702236778121005,
      "best_answer": "Hume Highway",
      "total_prob": 0.7430273923019195,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 54,
      "generated_answer": "Lawrence Technological University",
      "gold_answers": [
        "University of North Texas"
      ],
      "reference_answer": "University of North Texas",
      "em_score": 0.0,
      "f1_score": 0.28571428571428575,
      "precision": 0.3333333333333333,
      "recall": 0.25,
      "individual_probs": {
        "University of North Texas": 0.28789286865200303
      },
      "individual_log_probs": {
        "University of North Texas": -1.2451668518965562
      },
      "max_prob": 0.28789286865200303,
      "max_log_prob": -1.2451668518965562,
      "best_answer": "University of North Texas",
      "total_prob": 0.28789286865200303,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 55,
      "generated_answer": "Humber Refinery.",
      "gold_answers": [
        "the A160"
      ],
      "reference_answer": "the A160",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "the A160": 5.1775299555385095e-08
      },
      "individual_log_probs": {
        "the A160": -16.776352643966675
      },
      "max_prob": 5.1775299555385095e-08,
      "max_log_prob": -16.776352643966675,
      "best_answer": "the A160",
      "total_prob": 5.1775299555385095e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 56,
      "generated_answer": "American",
      "gold_answers": [
        "American"
      ],
      "reference_answer": "American",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "American": 0.9985616659952714
      },
      "individual_log_probs": {
        "American": -0.0014393694000318646
      },
      "max_prob": 0.9985616659952714,
      "max_log_prob": -0.0014393694000318646,
      "best_answer": "American",
      "total_prob": 0.9985616659952714,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 57,
      "generated_answer": "Red Bhutlah and Trinidad Douglah.",
      "gold_answers": [
        "\"Capsicum chinense\""
      ],
      "reference_answer": "\"Capsicum chinense\"",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "\"Capsicum chinense\"": 9.410783967419876e-10
      },
      "individual_log_probs": {
        "\"Capsicum chinense\"": -20.783994667654042
      },
      "max_prob": 9.410783967419876e-10,
      "max_log_prob": -20.783994667654042,
      "best_answer": "\"Capsicum chinense\"",
      "total_prob": 9.410783967419876e-10,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 58,
      "generated_answer": "Hillary Clinton",
      "gold_answers": [
        "Hillary Clinton"
      ],
      "reference_answer": "Hillary Clinton",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Hillary Clinton": 0.46599753804053123
      },
      "individual_log_probs": {
        "Hillary Clinton": -0.7635749280452728
      },
      "max_prob": 0.46599753804053123,
      "max_log_prob": -0.7635749280452728,
      "best_answer": "Hillary Clinton",
      "total_prob": 0.46599753804053123,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 59,
      "generated_answer": "Lynyrd Skynyrd",
      "gold_answers": [
        "Lynyrd Skynyrd"
      ],
      "reference_answer": "Lynyrd Skynyrd",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Lynyrd Skynyrd": 0.9802370263462217
      },
      "individual_log_probs": {
        "Lynyrd Skynyrd": -0.01996087294321569
      },
      "max_prob": 0.9802370263462217,
      "max_log_prob": -0.01996087294321569,
      "best_answer": "Lynyrd Skynyrd",
      "total_prob": 0.9802370263462217,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 60,
      "generated_answer": "Rosenrot",
      "gold_answers": [
        "Herzeleid"
      ],
      "reference_answer": "Herzeleid",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Herzeleid": 0.18637985133296706
      },
      "individual_log_probs": {
        "Herzeleid": -1.6799684762804503
      },
      "max_prob": 0.18637985133296706,
      "max_log_prob": -1.6799684762804503,
      "best_answer": "Herzeleid",
      "total_prob": 0.18637985133296706,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 61,
      "generated_answer": "1897",
      "gold_answers": [
        "1897"
      ],
      "reference_answer": "1897",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1897": 0.9988054012750999
      },
      "individual_log_probs": {
        "1897": -0.0011953128267236934
      },
      "max_prob": 0.9988054012750999,
      "max_log_prob": -0.0011953128267236934,
      "best_answer": "1897",
      "total_prob": 0.9988054012750999,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 62,
      "generated_answer": "Ahmed Elmohamady",
      "gold_answers": [
        "Ahmed Elmohamady"
      ],
      "reference_answer": "Ahmed Elmohamady",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Ahmed Elmohamady": 0.9314928489267136
      },
      "individual_log_probs": {
        "Ahmed Elmohamady": -0.0709667659139086
      },
      "max_prob": 0.9314928489267136,
      "max_log_prob": -0.0709667659139086,
      "best_answer": "Ahmed Elmohamady",
      "total_prob": 0.9314928489267136,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 63,
      "generated_answer": "Stop-motion animation.",
      "gold_answers": [
        "animation"
      ],
      "reference_answer": "animation",
      "em_score": 0.0,
      "f1_score": 0.6666666666666666,
      "precision": 0.5,
      "recall": 1.0,
      "individual_probs": {
        "animation": 3.505214780979194e-05
      },
      "individual_log_probs": {
        "animation": -10.258673667907715
      },
      "max_prob": 3.505214780979194e-05,
      "max_log_prob": -10.258673667907715,
      "best_answer": "animation",
      "total_prob": 3.505214780979194e-05,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 64,
      "generated_answer": "Jeff Healey",
      "gold_answers": [
        "Jeff Healey"
      ],
      "reference_answer": "Jeff Healey",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Jeff Healey": 0.9997269580212012
      },
      "individual_log_probs": {
        "Jeff Healey": -0.0002730792615466271
      },
      "max_prob": 0.9997269580212012,
      "max_log_prob": -0.0002730792615466271,
      "best_answer": "Jeff Healey",
      "total_prob": 0.9997269580212012,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 65,
      "generated_answer": "British Armed Forces",
      "gold_answers": [
        "British Armed Forces"
      ],
      "reference_answer": "British Armed Forces",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "British Armed Forces": 0.5014100679722996
      },
      "individual_log_probs": {
        "British Armed Forces": -0.6903310137381595
      },
      "max_prob": 0.5014100679722996,
      "max_log_prob": -0.6903310137381595,
      "best_answer": "British Armed Forces",
      "total_prob": 0.5014100679722996,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 66,
      "generated_answer": "Kadhalan",
      "gold_answers": [
        "Kadhalan"
      ],
      "reference_answer": "Kadhalan",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Kadhalan": 0.9994120886330935
      },
      "individual_log_probs": {
        "Kadhalan": -0.0005880842545593623
      },
      "max_prob": 0.9994120886330935,
      "max_log_prob": -0.0005880842545593623,
      "best_answer": "Kadhalan",
      "total_prob": 0.9994120886330935,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 67,
      "generated_answer": "Cherepanov Hill",
      "gold_answers": [
        "Cherepanov Hill"
      ],
      "reference_answer": "Cherepanov Hill",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Cherepanov Hill": 0.9959169829070919
      },
      "individual_log_probs": {
        "Cherepanov Hill": -0.004091375366272132
      },
      "max_prob": 0.9959169829070919,
      "max_log_prob": -0.004091375366272132,
      "best_answer": "Cherepanov Hill",
      "total_prob": 0.9959169829070919,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 68,
      "generated_answer": "Arantxa Sánchez Vicario",
      "gold_answers": [
        "\"Arantxa\" Sánchez Vicario"
      ],
      "reference_answer": "\"Arantxa\" Sánchez Vicario",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "\"Arantxa\" Sánchez Vicario": 2.400821324945228e-15
      },
      "individual_log_probs": {
        "\"Arantxa\" Sánchez Vicario": -33.66296549737308
      },
      "max_prob": 2.400821324945228e-15,
      "max_log_prob": -33.66296549737308,
      "best_answer": "\"Arantxa\" Sánchez Vicario",
      "total_prob": 2.400821324945228e-15,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 69,
      "generated_answer": "University of Alabama",
      "gold_answers": [
        "University of Alabama"
      ],
      "reference_answer": "University of Alabama",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "University of Alabama": 0.945267208264012
      },
      "individual_log_probs": {
        "University of Alabama": -0.05628763138975046
      },
      "max_prob": 0.945267208264012,
      "max_log_prob": -0.05628763138975046,
      "best_answer": "University of Alabama",
      "total_prob": 0.945267208264012,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 70,
      "generated_answer": "Pizza Hut",
      "gold_answers": [
        "Pizza Hut"
      ],
      "reference_answer": "Pizza Hut",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Pizza Hut": 0.8975415990655964
      },
      "individual_log_probs": {
        "Pizza Hut": -0.10809580976001598
      },
      "max_prob": 0.8975415990655964,
      "max_log_prob": -0.10809580976001598,
      "best_answer": "Pizza Hut",
      "total_prob": 0.8975415990655964,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 71,
      "generated_answer": "1968",
      "gold_answers": [
        "1939"
      ],
      "reference_answer": "1939",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1939": 4.2577537010608794e-06
      },
      "individual_log_probs": {
        "1939": -12.366768836975098
      },
      "max_prob": 4.2577537010608794e-06,
      "max_log_prob": -12.366768836975098,
      "best_answer": "1939",
      "total_prob": 4.2577537010608794e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 72,
      "generated_answer": "1962",
      "gold_answers": [
        "1962"
      ],
      "reference_answer": "1962",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1962": 0.9990748389310022
      },
      "individual_log_probs": {
        "1962": -0.0009255892946384847
      },
      "max_prob": 0.9990748389310022,
      "max_log_prob": -0.0009255892946384847,
      "best_answer": "1962",
      "total_prob": 0.9990748389310022,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 73,
      "generated_answer": "Metreon",
      "gold_answers": [
        "Metreon"
      ],
      "reference_answer": "Metreon",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Metreon": 0.998566524295611
      },
      "individual_log_probs": {
        "Metreon": -0.0014345041136039072
      },
      "max_prob": 0.998566524295611,
      "max_log_prob": -0.0014345041136039072,
      "best_answer": "Metreon",
      "total_prob": 0.998566524295611,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 74,
      "generated_answer": "Viktor Uspaskich",
      "gold_answers": [
        "Viktor Uspaskich"
      ],
      "reference_answer": "Viktor Uspaskich",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Viktor Uspaskich": 0.9993219308511901
      },
      "individual_log_probs": {
        "Viktor Uspaskich": -0.0006782991416685036
      },
      "max_prob": 0.9993219308511901,
      "max_log_prob": -0.0006782991416685036,
      "best_answer": "Viktor Uspaskich",
      "total_prob": 0.9993219308511901,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 75,
      "generated_answer": "Spacemen 3",
      "gold_answers": [
        "Spacemen 3"
      ],
      "reference_answer": "Spacemen 3",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Spacemen 3": 0.6789998753921853
      },
      "individual_log_probs": {
        "Spacemen 3": -0.3871343349401215
      },
      "max_prob": 0.6789998753921853,
      "max_log_prob": -0.3871343349401215,
      "best_answer": "Spacemen 3",
      "total_prob": 0.6789998753921853,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 76,
      "generated_answer": "Stephen King",
      "gold_answers": [
        "Stephen King"
      ],
      "reference_answer": "Stephen King",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Stephen King": 0.9989237377727849
      },
      "individual_log_probs": {
        "Stephen King": -0.0010768418133011437
      },
      "max_prob": 0.9989237377727849,
      "max_log_prob": -0.0010768418133011437,
      "best_answer": "Stephen King",
      "total_prob": 0.9989237377727849,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 77,
      "generated_answer": "classical theory of electromagnetic radiation",
      "gold_answers": [
        "classical theory of electromagnetic radiation"
      ],
      "reference_answer": "classical theory of electromagnetic radiation",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "classical theory of electromagnetic radiation": 0.7761911540376748
      },
      "individual_log_probs": {
        "classical theory of electromagnetic radiation": -0.2533564566110158
      },
      "max_prob": 0.7761911540376748,
      "max_log_prob": -0.2533564566110158,
      "best_answer": "classical theory of electromagnetic radiation",
      "total_prob": 0.7761911540376748,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 78,
      "generated_answer": "1979",
      "gold_answers": [
        "The London Connection"
      ],
      "reference_answer": "The London Connection",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "The London Connection": 0.1436311855406764
      },
      "individual_log_probs": {
        "The London Connection": -1.9405064764425788
      },
      "max_prob": 0.1436311855406764,
      "max_log_prob": -1.9405064764425788,
      "best_answer": "The London Connection",
      "total_prob": 0.1436311855406764,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 79,
      "generated_answer": "American",
      "gold_answers": [
        "Mexican"
      ],
      "reference_answer": "Mexican",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Mexican": 5.123776579921266e-05
      },
      "individual_log_probs": {
        "Mexican": -9.879033684555907
      },
      "max_prob": 5.123776579921266e-05,
      "max_log_prob": -9.879033684555907,
      "best_answer": "Mexican",
      "total_prob": 5.123776579921266e-05,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 80,
      "generated_answer": "December 7, 2008",
      "gold_answers": [
        "December 7, 2008"
      ],
      "reference_answer": "December 7, 2008",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "December 7, 2008": 0.9962618832171714
      },
      "individual_log_probs": {
        "December 7, 2008": -0.003745121001877294
      },
      "max_prob": 0.9962618832171714,
      "max_log_prob": -0.003745121001877294,
      "best_answer": "December 7, 2008",
      "total_prob": 0.9962618832171714,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 81,
      "generated_answer": "Yes",
      "gold_answers": [
        "yes"
      ],
      "reference_answer": "yes",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "yes": 0.0019118697378210706
      },
      "individual_log_probs": {
        "yes": -6.259673595428467
      },
      "max_prob": 0.0019118697378210706,
      "max_log_prob": -6.259673595428467,
      "best_answer": "yes",
      "total_prob": 0.0019118697378210706,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 82,
      "generated_answer": "Football.",
      "gold_answers": [
        "Football"
      ],
      "reference_answer": "Football",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Football": 0.9021099886325742
      },
      "individual_log_probs": {
        "Football": -0.10301882773637772
      },
      "max_prob": 0.9021099886325742,
      "max_log_prob": -0.10301882773637772,
      "best_answer": "Football",
      "total_prob": 0.9021099886325742,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 83,
      "generated_answer": "Betty X",
      "gold_answers": [
        "Betty X"
      ],
      "reference_answer": "Betty X",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Betty X": 0.6812705400526987
      },
      "individual_log_probs": {
        "Betty X": -0.38379578292313
      },
      "max_prob": 0.6812705400526987,
      "max_log_prob": -0.38379578292313,
      "best_answer": "Betty X",
      "total_prob": 0.6812705400526987,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 84,
      "generated_answer": "Extreme Pizza",
      "gold_answers": [
        "Extreme Pizza"
      ],
      "reference_answer": "Extreme Pizza",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Extreme Pizza": 0.9911495195381058
      },
      "individual_log_probs": {
        "Extreme Pizza": -0.008889878597983625
      },
      "max_prob": 0.9911495195381058,
      "max_log_prob": -0.008889878597983625,
      "best_answer": "Extreme Pizza",
      "total_prob": 0.9911495195381058,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 85,
      "generated_answer": "Anna Mae Bullock",
      "gold_answers": [
        "Anna Mae Bullock"
      ],
      "reference_answer": "Anna Mae Bullock",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Anna Mae Bullock": 0.9962065073195585
      },
      "individual_log_probs": {
        "Anna Mae Bullock": -0.0038007062225915433
      },
      "max_prob": 0.9962065073195585,
      "max_log_prob": -0.0038007062225915433,
      "best_answer": "Anna Mae Bullock",
      "total_prob": 0.9962065073195585,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 86,
      "generated_answer": "Michie Stadium",
      "gold_answers": [
        "Michie Stadium"
      ],
      "reference_answer": "Michie Stadium",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Michie Stadium": 0.9963992793648657
      },
      "individual_log_probs": {
        "Michie Stadium": -0.0036072188331672805
      },
      "max_prob": 0.9963992793648657,
      "max_log_prob": -0.0036072188331672805,
      "best_answer": "Michie Stadium",
      "total_prob": 0.9963992793648657,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 87,
      "generated_answer": "Pacific Ocean",
      "gold_answers": [
        "the Pacific Ocean"
      ],
      "reference_answer": "the Pacific Ocean",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "the Pacific Ocean": 0.001724239242933463
      },
      "individual_log_probs": {
        "the Pacific Ocean": -6.3629693443654105
      },
      "max_prob": 0.001724239242933463,
      "max_log_prob": -6.3629693443654105,
      "best_answer": "the Pacific Ocean",
      "total_prob": 0.001724239242933463,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 88,
      "generated_answer": "Angela Nissel",
      "gold_answers": [
        "Angela R. Nissel"
      ],
      "reference_answer": "Angela R. Nissel",
      "em_score": 0.0,
      "f1_score": 0.8,
      "precision": 1.0,
      "recall": 0.6666666666666666,
      "individual_probs": {
        "Angela R. Nissel": 4.219853681494541e-09
      },
      "individual_log_probs": {
        "Angela R. Nissel": -19.283465382131226
      },
      "max_prob": 4.219853681494541e-09,
      "max_log_prob": -19.283465382131226,
      "best_answer": "Angela R. Nissel",
      "total_prob": 4.219853681494541e-09,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 89,
      "generated_answer": "LyondellBasell.",
      "gold_answers": [
        "Netherlands"
      ],
      "reference_answer": "Netherlands",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Netherlands": 0.00161332426301438
      },
      "individual_log_probs": {
        "Netherlands": -6.429458469036035
      },
      "max_prob": 0.00161332426301438,
      "max_log_prob": -6.429458469036035,
      "best_answer": "Netherlands",
      "total_prob": 0.00161332426301438,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 90,
      "generated_answer": "Alessandro Nannini",
      "gold_answers": [
        "Alessandro Nannini"
      ],
      "reference_answer": "Alessandro Nannini",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Alessandro Nannini": 0.9451718783498819
      },
      "individual_log_probs": {
        "Alessandro Nannini": -0.05638848617516601
      },
      "max_prob": 0.9451718783498819,
      "max_log_prob": -0.05638848617516601,
      "best_answer": "Alessandro Nannini",
      "total_prob": 0.9451718783498819,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 91,
      "generated_answer": "Theo van Gogh",
      "gold_answers": [
        "Theodorus \"Theo\" van Gogh"
      ],
      "reference_answer": "Theodorus \"Theo\" van Gogh",
      "em_score": 0.0,
      "f1_score": 0.8571428571428571,
      "precision": 1.0,
      "recall": 0.75,
      "individual_probs": {
        "Theodorus \"Theo\" van Gogh": 1.9408498638347856e-08
      },
      "individual_log_probs": {
        "Theodorus \"Theo\" van Gogh": -17.75755479266195
      },
      "max_prob": 1.9408498638347856e-08,
      "max_log_prob": -17.75755479266195,
      "best_answer": "Theodorus \"Theo\" van Gogh",
      "total_prob": 1.9408498638347856e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 92,
      "generated_answer": "Indian Rebellion of 1857",
      "gold_answers": [
        "Indian Rebellion of 1857"
      ],
      "reference_answer": "Indian Rebellion of 1857",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Indian Rebellion of 1857": 0.6807647610152199
      },
      "individual_log_probs": {
        "Indian Rebellion of 1857": -0.38453846420360804
      },
      "max_prob": 0.6807647610152199,
      "max_log_prob": -0.38453846420360804,
      "best_answer": "Indian Rebellion of 1857",
      "total_prob": 0.6807647610152199,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 93,
      "generated_answer": "Yes.",
      "gold_answers": [
        "yes"
      ],
      "reference_answer": "yes",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "yes": 0.0008358049480924798
      },
      "individual_log_probs": {
        "yes": -7.087115287780762
      },
      "max_prob": 0.0008358049480924798,
      "max_log_prob": -7.087115287780762,
      "best_answer": "yes",
      "total_prob": 0.0008358049480924798,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 94,
      "generated_answer": "Ludovico Einaudi collaborated with Canzoniere Grecanico Salentino on the album Diario Mali",
      "gold_answers": [
        "Italian pianist and composer"
      ],
      "reference_answer": "Italian pianist and composer",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Italian pianist and composer": 4.342789377129072e-06
      },
      "individual_log_probs": {
        "Italian pianist and composer": -12.346993702679697
      },
      "max_prob": 4.342789377129072e-06,
      "max_log_prob": -12.346993702679697,
      "best_answer": "Italian pianist and composer",
      "total_prob": 4.342789377129072e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 95,
      "generated_answer": "Daesung",
      "gold_answers": [
        "actress"
      ],
      "reference_answer": "actress",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "actress": 0.001086028778140613
      },
      "individual_log_probs": {
        "actress": -6.8252275586128235
      },
      "max_prob": 0.001086028778140613,
      "max_log_prob": -6.8252275586128235,
      "best_answer": "actress",
      "total_prob": 0.001086028778140613,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 96,
      "generated_answer": "Amsterdam",
      "gold_answers": [
        "Amsterdam"
      ],
      "reference_answer": "Amsterdam",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Amsterdam": 0.9939855401759947
      },
      "individual_log_probs": {
        "Amsterdam": -0.00603261953801848
      },
      "max_prob": 0.9939855401759947,
      "max_log_prob": -0.00603261953801848,
      "best_answer": "Amsterdam",
      "total_prob": 0.9939855401759947,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 97,
      "generated_answer": "No",
      "gold_answers": [
        "no"
      ],
      "reference_answer": "no",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "no": 0.0013395126455039684
      },
      "individual_log_probs": {
        "no": -6.61544942855835
      },
      "max_prob": 0.0013395126455039684,
      "max_log_prob": -6.61544942855835,
      "best_answer": "no",
      "total_prob": 0.0013395126455039684,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 98,
      "generated_answer": "Nickelodeon",
      "gold_answers": [
        "Nickelodeon"
      ],
      "reference_answer": "Nickelodeon",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Nickelodeon": 0.9878192114971214
      },
      "individual_log_probs": {
        "Nickelodeon": -0.012255582292596046
      },
      "max_prob": 0.9878192114971214,
      "max_log_prob": -0.012255582292596046,
      "best_answer": "Nickelodeon",
      "total_prob": 0.9878192114971214,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    },
    {
      "sample_idx": 99,
      "generated_answer": "On the Road with Austin and Santino.",
      "gold_answers": [
        "Project Runway"
      ],
      "reference_answer": "Project Runway",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Project Runway": 0.0633333504279168
      },
      "individual_log_probs": {
        "Project Runway": -2.7593432255753214
      },
      "max_prob": 0.0633333504279168,
      "max_log_prob": -2.7593432255753214,
      "best_answer": "Project Runway",
      "total_prob": 0.0633333504279168,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.5
    }
  ]
}