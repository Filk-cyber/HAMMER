{
  "metrics": {
    "weight_w": 0.3,
    "input_file": "/home/jiangjp/trace-idea/data/hotpotqa/hotpotqa_dev100ideal_with_reasoning_chains_modify_w03.json",
    "total_samples": 100,
    "exact_match": 0.68,
    "f1": 0.7461190476190476,
    "precision": 0.7494999999999998,
    "recall": 0.7616666666666666,
    "avg_max_log_prob": -4.015716609676162,
    "avg_max_prob": 0.5941748776636855,
    "avg_total_prob": 0.5941748776636855,
    "valid_max_prob_samples": 100,
    "invalid_max_prob_samples": 0,
    "avg_answer_count": 1.0,
    "avg_valid_answer_count": 1.0
  },
  "sample_info": [
    {
      "sample_idx": 0,
      "generated_answer": "Yes.",
      "gold_answers": [
        "no"
      ],
      "reference_answer": "no",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "no": 0.00015860208077461257
      },
      "individual_log_probs": {
        "no": -8.749112129211426
      },
      "max_prob": 0.00015860208077461257,
      "max_log_prob": -8.749112129211426,
      "best_answer": "no",
      "total_prob": 0.00015860208077461257,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 1,
      "generated_answer": "University of Delaware",
      "gold_answers": [
        "University of Delaware"
      ],
      "reference_answer": "University of Delaware",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "University of Delaware": 0.6490143327126258
      },
      "individual_log_probs": {
        "University of Delaware": -0.43230047821893436
      },
      "max_prob": 0.6490143327126258,
      "max_log_prob": -0.43230047821893436,
      "best_answer": "University of Delaware",
      "total_prob": 0.6490143327126258,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 2,
      "generated_answer": "February 26, 2009",
      "gold_answers": [
        "NBC"
      ],
      "reference_answer": "NBC",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "NBC": 0.00015082924593739434
      },
      "individual_log_probs": {
        "NBC": -8.799362182617188
      },
      "max_prob": 0.00015082924593739434,
      "max_log_prob": -8.799362182617188,
      "best_answer": "NBC",
      "total_prob": 0.00015082924593739434,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 3,
      "generated_answer": "Flowering plants.",
      "gold_answers": [
        "genus"
      ],
      "reference_answer": "genus",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "genus": 0.03715584263439374
      },
      "individual_log_probs": {
        "genus": -3.2926342487335205
      },
      "max_prob": 0.03715584263439374,
      "max_log_prob": -3.2926342487335205,
      "best_answer": "genus",
      "total_prob": 0.03715584263439374,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 4,
      "generated_answer": "Kirk Fogg.",
      "gold_answers": [
        "Jeff Sutphen"
      ],
      "reference_answer": "Jeff Sutphen",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Jeff Sutphen": 0.15186892109230768
      },
      "individual_log_probs": {
        "Jeff Sutphen": -1.8847374914180364
      },
      "max_prob": 0.15186892109230768,
      "max_log_prob": -1.8847374914180364,
      "best_answer": "Jeff Sutphen",
      "total_prob": 0.15186892109230768,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 5,
      "generated_answer": "The Forest of Bowland.",
      "gold_answers": [
        "the Bowland Fells"
      ],
      "reference_answer": "the Bowland Fells",
      "em_score": 0.0,
      "f1_score": 0.4,
      "precision": 0.3333333333333333,
      "recall": 0.5,
      "individual_probs": {
        "the Bowland Fells": 7.97658105857611e-06
      },
      "individual_log_probs": {
        "the Bowland Fells": -11.739000677083595
      },
      "max_prob": 7.97658105857611e-06,
      "max_log_prob": -11.739000677083595,
      "best_answer": "the Bowland Fells",
      "total_prob": 7.97658105857611e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 6,
      "generated_answer": "Daft Punk",
      "gold_answers": [
        "Daft Punk"
      ],
      "reference_answer": "Daft Punk",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Daft Punk": 0.9998327759505139
      },
      "individual_log_probs": {
        "Daft Punk": -0.0001672380329864609
      },
      "max_prob": 0.9998327759505139,
      "max_log_prob": -0.0001672380329864609,
      "best_answer": "Daft Punk",
      "total_prob": 0.9998327759505139,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 7,
      "generated_answer": "3rd Rock from the Sun",
      "gold_answers": [
        "3rd Rock from the Sun"
      ],
      "reference_answer": "3rd Rock from the Sun",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "3rd Rock from the Sun": 0.9369628238659439
      },
      "individual_log_probs": {
        "3rd Rock from the Sun": -0.06511167323418476
      },
      "max_prob": 0.9369628238659439,
      "max_log_prob": -0.06511167323418476,
      "best_answer": "3rd Rock from the Sun",
      "total_prob": 0.9369628238659439,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 8,
      "generated_answer": "The Island (2005 film)",
      "gold_answers": [
        "The Island"
      ],
      "reference_answer": "The Island",
      "em_score": 0.0,
      "f1_score": 0.5,
      "precision": 0.3333333333333333,
      "recall": 1.0,
      "individual_probs": {
        "The Island": 0.972999179931072
      },
      "individual_log_probs": {
        "The Island": -0.027372039621695876
      },
      "max_prob": 0.972999179931072,
      "max_log_prob": -0.027372039621695876,
      "best_answer": "The Island",
      "total_prob": 0.972999179931072,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 9,
      "generated_answer": "The Great Mouse Detective",
      "gold_answers": [
        "The Great Mouse Detective"
      ],
      "reference_answer": "The Great Mouse Detective",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "The Great Mouse Detective": 0.9509235217240695
      },
      "individual_log_probs": {
        "The Great Mouse Detective": -0.05032163846749427
      },
      "max_prob": 0.9509235217240695,
      "max_log_prob": -0.05032163846749427,
      "best_answer": "The Great Mouse Detective",
      "total_prob": 0.9509235217240695,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 10,
      "generated_answer": "2003",
      "gold_answers": [
        "20 March to 1 May 2003"
      ],
      "reference_answer": "20 March to 1 May 2003",
      "em_score": 0.0,
      "f1_score": 0.2857142857142857,
      "precision": 1.0,
      "recall": 0.16666666666666666,
      "individual_probs": {
        "20 March to 1 May 2003": 0.05384076848588132
      },
      "individual_log_probs": {
        "20 March to 1 May 2003": -2.9217243202356187
      },
      "max_prob": 0.05384076848588132,
      "max_log_prob": -2.9217243202356187,
      "best_answer": "20 March to 1 May 2003",
      "total_prob": 0.05384076848588132,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 11,
      "generated_answer": "A genus of flowering plant.",
      "gold_answers": [
        "plant"
      ],
      "reference_answer": "plant",
      "em_score": 0.0,
      "f1_score": 0.4,
      "precision": 0.25,
      "recall": 1.0,
      "individual_probs": {
        "plant": 0.00024369166958133483
      },
      "individual_log_probs": {
        "plant": -8.31960678100586
      },
      "max_prob": 0.00024369166958133483,
      "max_log_prob": -8.31960678100586,
      "best_answer": "plant",
      "total_prob": 0.00024369166958133483,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 12,
      "generated_answer": "Montclair State University.",
      "gold_answers": [
        "Montclair State University"
      ],
      "reference_answer": "Montclair State University",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Montclair State University": 0.9986985630051187
      },
      "individual_log_probs": {
        "Montclair State University": -0.001302284599489667
      },
      "max_prob": 0.9986985630051187,
      "max_log_prob": -0.001302284599489667,
      "best_answer": "Montclair State University",
      "total_prob": 0.9986985630051187,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 13,
      "generated_answer": "Soha Ali Khan",
      "gold_answers": [
        "Soha Ali Khan"
      ],
      "reference_answer": "Soha Ali Khan",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Soha Ali Khan": 0.9997337486215627
      },
      "individual_log_probs": {
        "Soha Ali Khan": -0.00026628682962837047
      },
      "max_prob": 0.9997337486215627,
      "max_log_prob": -0.00026628682962837047,
      "best_answer": "Soha Ali Khan",
      "total_prob": 0.9997337486215627,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 14,
      "generated_answer": "Yes",
      "gold_answers": [
        "yes"
      ],
      "reference_answer": "yes",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "yes": 0.000964398040952211
      },
      "individual_log_probs": {
        "yes": -6.944006443023682
      },
      "max_prob": 0.000964398040952211,
      "max_log_prob": -6.944006443023682,
      "best_answer": "yes",
      "total_prob": 0.000964398040952211,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 15,
      "generated_answer": "Bodo League massacre.",
      "gold_answers": [
        "Bodo League massacre"
      ],
      "reference_answer": "Bodo League massacre",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Bodo League massacre": 0.9771481345139128
      },
      "individual_log_probs": {
        "Bodo League massacre": -0.023117016617106856
      },
      "max_prob": 0.9771481345139128,
      "max_log_prob": -0.023117016617106856,
      "best_answer": "Bodo League massacre",
      "total_prob": 0.9771481345139128,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 16,
      "generated_answer": "Ariocarpus",
      "gold_answers": [
        "Ariocarpus"
      ],
      "reference_answer": "Ariocarpus",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Ariocarpus": 0.9836779071046962
      },
      "individual_log_probs": {
        "Ariocarpus": -0.016456765692254294
      },
      "max_prob": 0.9836779071046962,
      "max_log_prob": -0.016456765692254294,
      "best_answer": "Ariocarpus",
      "total_prob": 0.9836779071046962,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 17,
      "generated_answer": "761",
      "gold_answers": [
        "761"
      ],
      "reference_answer": "761",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "761": 0.9918668786911444
      },
      "individual_log_probs": {
        "761": -0.008166375569999218
      },
      "max_prob": 0.9918668786911444,
      "max_log_prob": -0.008166375569999218,
      "best_answer": "761",
      "total_prob": 0.9918668786911444,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 18,
      "generated_answer": "Cnut the Great.",
      "gold_answers": [
        "Cnut the Great"
      ],
      "reference_answer": "Cnut the Great",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Cnut the Great": 0.9467963047600886
      },
      "individual_log_probs": {
        "Cnut the Great": -0.05467130422266564
      },
      "max_prob": 0.9467963047600886,
      "max_log_prob": -0.05467130422266564,
      "best_answer": "Cnut the Great",
      "total_prob": 0.9467963047600886,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 19,
      "generated_answer": "Channel V",
      "gold_answers": [
        "Channel V"
      ],
      "reference_answer": "Channel V",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Channel V": 0.9990735289598308
      },
      "individual_log_probs": {
        "Channel V": -0.0009269004797261005
      },
      "max_prob": 0.9990735289598308,
      "max_log_prob": -0.0009269004797261005,
      "best_answer": "Channel V",
      "total_prob": 0.9990735289598308,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 20,
      "generated_answer": "Albert Camus",
      "gold_answers": [
        "Albert Camus"
      ],
      "reference_answer": "Albert Camus",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Albert Camus": 0.9718682047565365
      },
      "individual_log_probs": {
        "Albert Camus": -0.028535075529362075
      },
      "max_prob": 0.9718682047565365,
      "max_log_prob": -0.028535075529362075,
      "best_answer": "Albert Camus",
      "total_prob": 0.9718682047565365,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 21,
      "generated_answer": "Archbishop Gilday",
      "gold_answers": [
        "Paul Marcinkus"
      ],
      "reference_answer": "Paul Marcinkus",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Paul Marcinkus": 7.541591871355145e-05
      },
      "individual_log_probs": {
        "Paul Marcinkus": -9.492492181711896
      },
      "max_prob": 7.541591871355145e-05,
      "max_log_prob": -9.492492181711896,
      "best_answer": "Paul Marcinkus",
      "total_prob": 7.541591871355145e-05,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 22,
      "generated_answer": "1852",
      "gold_answers": [
        "1904"
      ],
      "reference_answer": "1904",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1904": 1.4209269730442604e-10
      },
      "individual_log_probs": {
        "1904": -22.674541473388672
      },
      "max_prob": 1.4209269730442604e-10,
      "max_log_prob": -22.674541473388672,
      "best_answer": "1904",
      "total_prob": 1.4209269730442604e-10,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 23,
      "generated_answer": "Ralph Fiennes",
      "gold_answers": [
        "Ralph Fiennes"
      ],
      "reference_answer": "Ralph Fiennes",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Ralph Fiennes": 0.9998363435824551
      },
      "individual_log_probs": {
        "Ralph Fiennes": -0.0001636698107176926
      },
      "max_prob": 0.9998363435824551,
      "max_log_prob": -0.0001636698107176926,
      "best_answer": "Ralph Fiennes",
      "total_prob": 0.9998363435824551,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 24,
      "generated_answer": "runner-up",
      "gold_answers": [
        "runner-up"
      ],
      "reference_answer": "runner-up",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "runner-up": 0.8904682469645833
      },
      "individual_log_probs": {
        "runner-up": -0.11600783442372631
      },
      "max_prob": 0.8904682469645833,
      "max_log_prob": -0.11600783442372631,
      "best_answer": "runner-up",
      "total_prob": 0.8904682469645833,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 25,
      "generated_answer": "Swedish",
      "gold_answers": [
        "Swedish"
      ],
      "reference_answer": "Swedish",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Swedish": 0.998579971018977
      },
      "individual_log_probs": {
        "Swedish": -0.0014210381776820213
      },
      "max_prob": 0.998579971018977,
      "max_log_prob": -0.0014210381776820213,
      "best_answer": "Swedish",
      "total_prob": 0.998579971018977,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 26,
      "generated_answer": "Vice",
      "gold_answers": [
        "Vice"
      ],
      "reference_answer": "Vice",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Vice": 0.9911590629251548
      },
      "individual_log_probs": {
        "Vice": -0.008880250039510429
      },
      "max_prob": 0.9911590629251548,
      "max_log_prob": -0.008880250039510429,
      "best_answer": "Vice",
      "total_prob": 0.9911590629251548,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 27,
      "generated_answer": "The Preppie Murder",
      "gold_answers": [
        "The Preppie Murder"
      ],
      "reference_answer": "The Preppie Murder",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "The Preppie Murder": 0.9589108723459878
      },
      "individual_log_probs": {
        "The Preppie Murder": -0.04195714653451432
      },
      "max_prob": 0.9589108723459878,
      "max_log_prob": -0.04195714653451432,
      "best_answer": "The Preppie Murder",
      "total_prob": 0.9589108723459878,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 28,
      "generated_answer": "Isolde Kostner",
      "gold_answers": [
        "Isolde Kostner"
      ],
      "reference_answer": "Isolde Kostner",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Isolde Kostner": 0.9878908020294148
      },
      "individual_log_probs": {
        "Isolde Kostner": -0.012183111604251451
      },
      "max_prob": 0.9878908020294148,
      "max_log_prob": -0.012183111604251451,
      "best_answer": "Isolde Kostner",
      "total_prob": 0.9878908020294148,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 29,
      "generated_answer": "Westwood Jr. High School",
      "gold_answers": [
        "Beverly Hills High School"
      ],
      "reference_answer": "Beverly Hills High School",
      "em_score": 0.0,
      "f1_score": 0.5,
      "precision": 0.5,
      "recall": 0.5,
      "individual_probs": {
        "Beverly Hills High School": 1.1887691532695134e-06
      },
      "individual_log_probs": {
        "Beverly Hills High School": -13.64259211110766
      },
      "max_prob": 1.1887691532695134e-06,
      "max_log_prob": -13.64259211110766,
      "best_answer": "Beverly Hills High School",
      "total_prob": 1.1887691532695134e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 30,
      "generated_answer": "1989",
      "gold_answers": [
        "fifth album"
      ],
      "reference_answer": "fifth album",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "fifth album": 9.625575269556517e-10
      },
      "individual_log_probs": {
        "fifth album": -20.76142728328705
      },
      "max_prob": 9.625575269556517e-10,
      "max_log_prob": -20.76142728328705,
      "best_answer": "fifth album",
      "total_prob": 9.625575269556517e-10,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 31,
      "generated_answer": "Welterweight",
      "gold_answers": [
        "Welterweight"
      ],
      "reference_answer": "Welterweight",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Welterweight": 0.9960267427170795
      },
      "individual_log_probs": {
        "Welterweight": -0.003981171640447201
      },
      "max_prob": 0.9960267427170795,
      "max_log_prob": -0.003981171640447201,
      "best_answer": "Welterweight",
      "total_prob": 0.9960267427170795,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 32,
      "generated_answer": "Times Beach",
      "gold_answers": [
        "Times Beach"
      ],
      "reference_answer": "Times Beach",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Times Beach": 0.9992884645143777
      },
      "individual_log_probs": {
        "Times Beach": -0.0007117887471395079
      },
      "max_prob": 0.9992884645143777,
      "max_log_prob": -0.0007117887471395079,
      "best_answer": "Times Beach",
      "total_prob": 0.9992884645143777,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 33,
      "generated_answer": "Beverly Hills Supper Club fire.",
      "gold_answers": [
        "Beverly Hills Supper Club fire"
      ],
      "reference_answer": "Beverly Hills Supper Club fire",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Beverly Hills Supper Club fire": 0.41995811617511736
      },
      "individual_log_probs": {
        "Beverly Hills Supper Club fire": -0.8676002960700089
      },
      "max_prob": 0.41995811617511736,
      "max_log_prob": -0.8676002960700089,
      "best_answer": "Beverly Hills Supper Club fire",
      "total_prob": 0.41995811617511736,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 34,
      "generated_answer": "Quarterback",
      "gold_answers": [
        "quarterback"
      ],
      "reference_answer": "quarterback",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "quarterback": 0.4592130120985799
      },
      "individual_log_probs": {
        "quarterback": -0.7782410979266388
      },
      "max_prob": 0.4592130120985799,
      "max_log_prob": -0.7782410979266388,
      "best_answer": "quarterback",
      "total_prob": 0.4592130120985799,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 35,
      "generated_answer": "Dusty Dvoracek",
      "gold_answers": [
        "Dusty Dvoracek"
      ],
      "reference_answer": "Dusty Dvoracek",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Dusty Dvoracek": 0.9997859338108488
      },
      "individual_log_probs": {
        "Dusty Dvoracek": -0.00021408910458831087
      },
      "max_prob": 0.9997859338108488,
      "max_log_prob": -0.00021408910458831087,
      "best_answer": "Dusty Dvoracek",
      "total_prob": 0.9997859338108488,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 36,
      "generated_answer": "No.",
      "gold_answers": [
        "no"
      ],
      "reference_answer": "no",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "no": 0.007858489326404063
      },
      "individual_log_probs": {
        "no": -4.846160888671875
      },
      "max_prob": 0.007858489326404063,
      "max_log_prob": -4.846160888671875,
      "best_answer": "no",
      "total_prob": 0.007858489326404063,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 37,
      "generated_answer": "Texas Rangers",
      "gold_answers": [
        "Texas Rangers"
      ],
      "reference_answer": "Texas Rangers",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Texas Rangers": 0.7563066610107337
      },
      "individual_log_probs": {
        "Texas Rangers": -0.27930834879316535
      },
      "max_prob": 0.7563066610107337,
      "max_log_prob": -0.27930834879316535,
      "best_answer": "Texas Rangers",
      "total_prob": 0.7563066610107337,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 38,
      "generated_answer": "Baltic, Germanic, and Thracian tribes.",
      "gold_answers": [
        "Germanic, Baltic and Thracian tribes"
      ],
      "reference_answer": "Germanic, Baltic and Thracian tribes",
      "em_score": 0.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Germanic, Baltic and Thracian tribes": 0.00012174472622008859
      },
      "individual_log_probs": {
        "Germanic, Baltic and Thracian tribes": -9.013584113407205
      },
      "max_prob": 0.00012174472622008859,
      "max_log_prob": -9.013584113407205,
      "best_answer": "Germanic, Baltic and Thracian tribes",
      "total_prob": 0.00012174472622008859,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 39,
      "generated_answer": "American",
      "gold_answers": [
        "American"
      ],
      "reference_answer": "American",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "American": 0.9994787312391036
      },
      "individual_log_probs": {
        "American": -0.0005214046686887741
      },
      "max_prob": 0.9994787312391036,
      "max_log_prob": -0.0005214046686887741,
      "best_answer": "American",
      "total_prob": 0.9994787312391036,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 40,
      "generated_answer": "Mario Lemieux",
      "gold_answers": [
        "Mario Lemieux"
      ],
      "reference_answer": "Mario Lemieux",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Mario Lemieux": 0.9998218100533741
      },
      "individual_log_probs": {
        "Mario Lemieux": -0.00017820582434069365
      },
      "max_prob": 0.9998218100533741,
      "max_log_prob": -0.00017820582434069365,
      "best_answer": "Mario Lemieux",
      "total_prob": 0.9998218100533741,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 41,
      "generated_answer": "Mumbai",
      "gold_answers": [
        "Mumbai"
      ],
      "reference_answer": "Mumbai",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Mumbai": 0.9988213184851787
      },
      "individual_log_probs": {
        "Mumbai": -0.0011793767062044935
      },
      "max_prob": 0.9988213184851787,
      "max_log_prob": -0.0011793767062044935,
      "best_answer": "Mumbai",
      "total_prob": 0.9988213184851787,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 42,
      "generated_answer": "Alexander Scriabin",
      "gold_answers": [
        "Alexander Scriabin"
      ],
      "reference_answer": "Alexander Scriabin",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Alexander Scriabin": 0.9921478090001183
      },
      "individual_log_probs": {
        "Alexander Scriabin": -0.007883181788628235
      },
      "max_prob": 0.9921478090001183,
      "max_log_prob": -0.007883181788628235,
      "best_answer": "Alexander Scriabin",
      "total_prob": 0.9921478090001183,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 43,
      "generated_answer": "4",
      "gold_answers": [
        "Their biggest hit was \"Tall Cool One\", first released in 1959"
      ],
      "reference_answer": "Their biggest hit was \"Tall Cool One\", first released in 1959",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Their biggest hit was \"Tall Cool One\", first released in 1959": 2.771468310452701e-13
      },
      "individual_log_probs": {
        "Their biggest hit was \"Tall Cool One\", first released in 1959": -28.914228953188285
      },
      "max_prob": 2.771468310452701e-13,
      "max_log_prob": -28.914228953188285,
      "best_answer": "Their biggest hit was \"Tall Cool One\", first released in 1959",
      "total_prob": 2.771468310452701e-13,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 44,
      "generated_answer": "Jawaharlal Nehru",
      "gold_answers": [
        "first Prime Minister of India"
      ],
      "reference_answer": "first Prime Minister of India",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "first Prime Minister of India": 0.0004469750915859251
      },
      "individual_log_probs": {
        "first Prime Minister of India": -7.713007688424739
      },
      "max_prob": 0.0004469750915859251,
      "max_log_prob": -7.713007688424739,
      "best_answer": "first Prime Minister of India",
      "total_prob": 0.0004469750915859251,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 45,
      "generated_answer": "Ireland",
      "gold_answers": [
        "Ireland"
      ],
      "reference_answer": "Ireland",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Ireland": 0.7961652006372208
      },
      "individual_log_probs": {
        "Ireland": -0.227948576181916
      },
      "max_prob": 0.7961652006372208,
      "max_log_prob": -0.227948576181916,
      "best_answer": "Ireland",
      "total_prob": 0.7961652006372208,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 46,
      "generated_answer": "72-78 passengers",
      "gold_answers": [
        "72-78"
      ],
      "reference_answer": "72-78",
      "em_score": 0.0,
      "f1_score": 0.6666666666666666,
      "precision": 0.5,
      "recall": 1.0,
      "individual_probs": {
        "72-78": 0.99775737707688
      },
      "individual_log_probs": {
        "72-78": -0.002245141367893666
      },
      "max_prob": 0.99775737707688,
      "max_log_prob": -0.002245141367893666,
      "best_answer": "72-78",
      "total_prob": 0.99775737707688,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 47,
      "generated_answer": "Heroica Matamoros",
      "gold_answers": [
        "Heroica Matamoros"
      ],
      "reference_answer": "Heroica Matamoros",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Heroica Matamoros": 0.9075683915321393
      },
      "individual_log_probs": {
        "Heroica Matamoros": -0.0969863531128965
      },
      "max_prob": 0.9075683915321393,
      "max_log_prob": -0.0969863531128965,
      "best_answer": "Heroica Matamoros",
      "total_prob": 0.9075683915321393,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 48,
      "generated_answer": "Benedict Arnold",
      "gold_answers": [
        "Benedict Arnold"
      ],
      "reference_answer": "Benedict Arnold",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Benedict Arnold": 0.9913677663022255
      },
      "individual_log_probs": {
        "Benedict Arnold": -0.00866970723649274
      },
      "max_prob": 0.9913677663022255,
      "max_log_prob": -0.00866970723649274,
      "best_answer": "Benedict Arnold",
      "total_prob": 0.9913677663022255,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 49,
      "generated_answer": "South Kesteven Sports Stadium",
      "gold_answers": [
        "South Kesteven Sports Stadium"
      ],
      "reference_answer": "South Kesteven Sports Stadium",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "South Kesteven Sports Stadium": 0.9544808263278252
      },
      "individual_log_probs": {
        "South Kesteven Sports Stadium": -0.046587723678833015
      },
      "max_prob": 0.9544808263278252,
      "max_log_prob": -0.046587723678833015,
      "best_answer": "South Kesteven Sports Stadium",
      "total_prob": 0.9544808263278252,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 50,
      "generated_answer": "Crown Princess Masako of Japan",
      "gold_answers": [
        "Aiko, Princess Toshi"
      ],
      "reference_answer": "Aiko, Princess Toshi",
      "em_score": 0.0,
      "f1_score": 0.25,
      "precision": 0.2,
      "recall": 0.3333333333333333,
      "individual_probs": {
        "Aiko, Princess Toshi": 0.18887305509988794
      },
      "individual_log_probs": {
        "Aiko, Princess Toshi": -1.6666801557294093
      },
      "max_prob": 0.18887305509988794,
      "max_log_prob": -1.6666801557294093,
      "best_answer": "Aiko, Princess Toshi",
      "total_prob": 0.18887305509988794,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 51,
      "generated_answer": "Darren McDermott",
      "gold_answers": [
        "Marco Antonio Barrera"
      ],
      "reference_answer": "Marco Antonio Barrera",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Marco Antonio Barrera": 1.4782609626373035e-08
      },
      "individual_log_probs": {
        "Marco Antonio Barrera": -18.029814372304827
      },
      "max_prob": 1.4782609626373035e-08,
      "max_log_prob": -18.029814372304827,
      "best_answer": "Marco Antonio Barrera",
      "total_prob": 1.4782609626373035e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 52,
      "generated_answer": "Iberian Peninsula",
      "gold_answers": [
        "Iberian Peninsula"
      ],
      "reference_answer": "Iberian Peninsula",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Iberian Peninsula": 0.901131154485876
      },
      "individual_log_probs": {
        "Iberian Peninsula": -0.1041044665003028
      },
      "max_prob": 0.901131154485876,
      "max_log_prob": -0.1041044665003028,
      "best_answer": "Iberian Peninsula",
      "total_prob": 0.901131154485876,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 53,
      "generated_answer": "Hume Highway",
      "gold_answers": [
        "Hume Highway"
      ],
      "reference_answer": "Hume Highway",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Hume Highway": 0.7509000596358035
      },
      "individual_log_probs": {
        "Hume Highway": -0.28648271245720025
      },
      "max_prob": 0.7509000596358035,
      "max_log_prob": -0.28648271245720025,
      "best_answer": "Hume Highway",
      "total_prob": 0.7509000596358035,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 54,
      "generated_answer": "Lawrence Technological University",
      "gold_answers": [
        "University of North Texas"
      ],
      "reference_answer": "University of North Texas",
      "em_score": 0.0,
      "f1_score": 0.28571428571428575,
      "precision": 0.3333333333333333,
      "recall": 0.25,
      "individual_probs": {
        "University of North Texas": 0.2878917704299589
      },
      "individual_log_probs": {
        "University of North Texas": -1.2451706665938218
      },
      "max_prob": 0.2878917704299589,
      "max_log_prob": -1.2451706665938218,
      "best_answer": "University of North Texas",
      "total_prob": 0.2878917704299589,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 55,
      "generated_answer": "Humber Refinery.",
      "gold_answers": [
        "the A160"
      ],
      "reference_answer": "the A160",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "the A160": 7.004846923782643e-08
      },
      "individual_log_probs": {
        "the A160": -16.47407841682434
      },
      "max_prob": 7.004846923782643e-08,
      "max_log_prob": -16.47407841682434,
      "best_answer": "the A160",
      "total_prob": 7.004846923782643e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 56,
      "generated_answer": "American",
      "gold_answers": [
        "American"
      ],
      "reference_answer": "American",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "American": 0.9963226151087273
      },
      "individual_log_probs": {
        "American": -0.0036841630935668945
      },
      "max_prob": 0.9963226151087273,
      "max_log_prob": -0.0036841630935668945,
      "best_answer": "American",
      "total_prob": 0.9963226151087273,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 57,
      "generated_answer": "Trinidad Moruga Scorpion",
      "gold_answers": [
        "\"Capsicum chinense\""
      ],
      "reference_answer": "\"Capsicum chinense\"",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "\"Capsicum chinense\"": 2.346899634024408e-06
      },
      "individual_log_probs": {
        "\"Capsicum chinense\"": -12.962415405527281
      },
      "max_prob": 2.346899634024408e-06,
      "max_log_prob": -12.962415405527281,
      "best_answer": "\"Capsicum chinense\"",
      "total_prob": 2.346899634024408e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 58,
      "generated_answer": "Hillary Clinton",
      "gold_answers": [
        "Hillary Clinton"
      ],
      "reference_answer": "Hillary Clinton",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Hillary Clinton": 0.46599398971887673
      },
      "individual_log_probs": {
        "Hillary Clinton": -0.7635825425386429
      },
      "max_prob": 0.46599398971887673,
      "max_log_prob": -0.7635825425386429,
      "best_answer": "Hillary Clinton",
      "total_prob": 0.46599398971887673,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 59,
      "generated_answer": "Lynyrd Skynyrd",
      "gold_answers": [
        "Lynyrd Skynyrd"
      ],
      "reference_answer": "Lynyrd Skynyrd",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Lynyrd Skynyrd": 0.9799054110078302
      },
      "individual_log_probs": {
        "Lynyrd Skynyrd": -0.02029923135557965
      },
      "max_prob": 0.9799054110078302,
      "max_log_prob": -0.02029923135557965,
      "best_answer": "Lynyrd Skynyrd",
      "total_prob": 0.9799054110078302,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 60,
      "generated_answer": "Herzeleid",
      "gold_answers": [
        "Herzeleid"
      ],
      "reference_answer": "Herzeleid",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Herzeleid": 0.5359841602917904
      },
      "individual_log_probs": {
        "Herzeleid": -0.6236506700424158
      },
      "max_prob": 0.5359841602917904,
      "max_log_prob": -0.6236506700424158,
      "best_answer": "Herzeleid",
      "total_prob": 0.5359841602917904,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 61,
      "generated_answer": "1897",
      "gold_answers": [
        "1897"
      ],
      "reference_answer": "1897",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1897": 0.9984308096845262
      },
      "individual_log_probs": {
        "1897": -0.0015704227840842577
      },
      "max_prob": 0.9984308096845262,
      "max_log_prob": -0.0015704227840842577,
      "best_answer": "1897",
      "total_prob": 0.9984308096845262,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 62,
      "generated_answer": "Ahmed Elmohamady",
      "gold_answers": [
        "Ahmed Elmohamady"
      ],
      "reference_answer": "Ahmed Elmohamady",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Ahmed Elmohamady": 0.996076415535707
      },
      "individual_log_probs": {
        "Ahmed Elmohamady": -0.0039313019151450135
      },
      "max_prob": 0.996076415535707,
      "max_log_prob": -0.0039313019151450135,
      "best_answer": "Ahmed Elmohamady",
      "total_prob": 0.996076415535707,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 63,
      "generated_answer": "3D animation",
      "gold_answers": [
        "animation"
      ],
      "reference_answer": "animation",
      "em_score": 0.0,
      "f1_score": 0.6666666666666666,
      "precision": 0.5,
      "recall": 1.0,
      "individual_probs": {
        "animation": 2.620916803873577e-05
      },
      "individual_log_probs": {
        "animation": -10.54940128326416
      },
      "max_prob": 2.620916803873577e-05,
      "max_log_prob": -10.54940128326416,
      "best_answer": "animation",
      "total_prob": 2.620916803873577e-05,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 64,
      "generated_answer": "Jeff Healey",
      "gold_answers": [
        "Jeff Healey"
      ],
      "reference_answer": "Jeff Healey",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Jeff Healey": 0.9996975288077296
      },
      "individual_log_probs": {
        "Jeff Healey": -0.0003025169459078825
      },
      "max_prob": 0.9996975288077296,
      "max_log_prob": -0.0003025169459078825,
      "best_answer": "Jeff Healey",
      "total_prob": 0.9996975288077296,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 65,
      "generated_answer": "the British Armed Forces",
      "gold_answers": [
        "British Armed Forces"
      ],
      "reference_answer": "British Armed Forces",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "British Armed Forces": 0.42831716593330754
      },
      "individual_log_probs": {
        "British Armed Forces": -0.8478913159360673
      },
      "max_prob": 0.42831716593330754,
      "max_log_prob": -0.8478913159360673,
      "best_answer": "British Armed Forces",
      "total_prob": 0.42831716593330754,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 66,
      "generated_answer": "Kadhalan",
      "gold_answers": [
        "Kadhalan"
      ],
      "reference_answer": "Kadhalan",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Kadhalan": 0.9983795512489293
      },
      "individual_log_probs": {
        "Kadhalan": -0.0016217630982282571
      },
      "max_prob": 0.9983795512489293,
      "max_log_prob": -0.0016217630982282571,
      "best_answer": "Kadhalan",
      "total_prob": 0.9983795512489293,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 67,
      "generated_answer": "Cherepanov Hill",
      "gold_answers": [
        "Cherepanov Hill"
      ],
      "reference_answer": "Cherepanov Hill",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Cherepanov Hill": 0.9945000223029649
      },
      "individual_log_probs": {
        "Cherepanov Hill": -0.005515158261800934
      },
      "max_prob": 0.9945000223029649,
      "max_log_prob": -0.005515158261800934,
      "best_answer": "Cherepanov Hill",
      "total_prob": 0.9945000223029649,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 68,
      "generated_answer": "Arantxa Sánchez Vicario",
      "gold_answers": [
        "\"Arantxa\" Sánchez Vicario"
      ],
      "reference_answer": "\"Arantxa\" Sánchez Vicario",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "\"Arantxa\" Sánchez Vicario": 3.2405290665779234e-15
      },
      "individual_log_probs": {
        "\"Arantxa\" Sánchez Vicario": -33.36303978628348
      },
      "max_prob": 3.2405290665779234e-15,
      "max_log_prob": -33.36303978628348,
      "best_answer": "\"Arantxa\" Sánchez Vicario",
      "total_prob": 3.2405290665779234e-15,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 69,
      "generated_answer": "University of Alabama",
      "gold_answers": [
        "University of Alabama"
      ],
      "reference_answer": "University of Alabama",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "University of Alabama": 0.9428443347604091
      },
      "individual_log_probs": {
        "University of Alabama": -0.05885408446022211
      },
      "max_prob": 0.9428443347604091,
      "max_log_prob": -0.05885408446022211,
      "best_answer": "University of Alabama",
      "total_prob": 0.9428443347604091,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 70,
      "generated_answer": "Pizza Hut",
      "gold_answers": [
        "Pizza Hut"
      ],
      "reference_answer": "Pizza Hut",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Pizza Hut": 0.9972235780958126
      },
      "individual_log_probs": {
        "Pizza Hut": -0.002780283312404208
      },
      "max_prob": 0.9972235780958126,
      "max_log_prob": -0.002780283312404208,
      "best_answer": "Pizza Hut",
      "total_prob": 0.9972235780958126,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 71,
      "generated_answer": "1964",
      "gold_answers": [
        "1939"
      ],
      "reference_answer": "1939",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "1939": 3.607577581251851e-06
      },
      "individual_log_probs": {
        "1939": -12.532474040985107
      },
      "max_prob": 3.607577581251851e-06,
      "max_log_prob": -12.532474040985107,
      "best_answer": "1939",
      "total_prob": 3.607577581251851e-06,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 72,
      "generated_answer": "1962",
      "gold_answers": [
        "1962"
      ],
      "reference_answer": "1962",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "1962": 0.9996963469717116
      },
      "individual_log_probs": {
        "1962": -0.0003036991402041167
      },
      "max_prob": 0.9996963469717116,
      "max_log_prob": -0.0003036991402041167,
      "best_answer": "1962",
      "total_prob": 0.9996963469717116,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 73,
      "generated_answer": "Metreon",
      "gold_answers": [
        "Metreon"
      ],
      "reference_answer": "Metreon",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Metreon": 0.9982846272803287
      },
      "individual_log_probs": {
        "Metreon": -0.0017168456561194034
      },
      "max_prob": 0.9982846272803287,
      "max_log_prob": -0.0017168456561194034,
      "best_answer": "Metreon",
      "total_prob": 0.9982846272803287,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 74,
      "generated_answer": "Viktor Uspaskich",
      "gold_answers": [
        "Viktor Uspaskich"
      ],
      "reference_answer": "Viktor Uspaskich",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Viktor Uspaskich": 0.9993850522344863
      },
      "individual_log_probs": {
        "Viktor Uspaskich": -0.0006151369234430604
      },
      "max_prob": 0.9993850522344863,
      "max_log_prob": -0.0006151369234430604,
      "best_answer": "Viktor Uspaskich",
      "total_prob": 0.9993850522344863,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 75,
      "generated_answer": "Spacemen 3",
      "gold_answers": [
        "Spacemen 3"
      ],
      "reference_answer": "Spacemen 3",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Spacemen 3": 0.8732681839221444
      },
      "individual_log_probs": {
        "Spacemen 3": -0.13551257224014535
      },
      "max_prob": 0.8732681839221444,
      "max_log_prob": -0.13551257224014535,
      "best_answer": "Spacemen 3",
      "total_prob": 0.8732681839221444,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 76,
      "generated_answer": "Stephen King.",
      "gold_answers": [
        "Stephen King"
      ],
      "reference_answer": "Stephen King",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Stephen King": 0.9988005214128182
      },
      "individual_log_probs": {
        "Stephen King": -0.0012001985373899515
      },
      "max_prob": 0.9988005214128182,
      "max_log_prob": -0.0012001985373899515,
      "best_answer": "Stephen King",
      "total_prob": 0.9988005214128182,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 77,
      "generated_answer": "classical theory of electromagnetic radiation",
      "gold_answers": [
        "classical theory of electromagnetic radiation"
      ],
      "reference_answer": "classical theory of electromagnetic radiation",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "classical theory of electromagnetic radiation": 0.7862788363045062
      },
      "individual_log_probs": {
        "classical theory of electromagnetic radiation": -0.2404437958950254
      },
      "max_prob": 0.7862788363045062,
      "max_log_prob": -0.2404437958950254,
      "best_answer": "classical theory of electromagnetic radiation",
      "total_prob": 0.7862788363045062,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 78,
      "generated_answer": "1979",
      "gold_answers": [
        "The London Connection"
      ],
      "reference_answer": "The London Connection",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "The London Connection": 0.14363140819596307
      },
      "individual_log_probs": {
        "The London Connection": -1.9405049262561533
      },
      "max_prob": 0.14363140819596307,
      "max_log_prob": -1.9405049262561533,
      "best_answer": "The London Connection",
      "total_prob": 0.14363140819596307,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 79,
      "generated_answer": "American",
      "gold_answers": [
        "Mexican"
      ],
      "reference_answer": "Mexican",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Mexican": 0.0004234512843615663
      },
      "individual_log_probs": {
        "Mexican": -7.767072081512197
      },
      "max_prob": 0.0004234512843615663,
      "max_log_prob": -7.767072081512197,
      "best_answer": "Mexican",
      "total_prob": 0.0004234512843615663,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 80,
      "generated_answer": "December 7, 2008",
      "gold_answers": [
        "December 7, 2008"
      ],
      "reference_answer": "December 7, 2008",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "December 7, 2008": 0.9987063148124476
      },
      "individual_log_probs": {
        "December 7, 2008": -0.001294522720648672
      },
      "max_prob": 0.9987063148124476,
      "max_log_prob": -0.001294522720648672,
      "best_answer": "December 7, 2008",
      "total_prob": 0.9987063148124476,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 81,
      "generated_answer": "Yes",
      "gold_answers": [
        "yes"
      ],
      "reference_answer": "yes",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "yes": 0.002077820133791776
      },
      "individual_log_probs": {
        "yes": -6.176435947418213
      },
      "max_prob": 0.002077820133791776,
      "max_log_prob": -6.176435947418213,
      "best_answer": "yes",
      "total_prob": 0.002077820133791776,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 82,
      "generated_answer": "Football.",
      "gold_answers": [
        "Football"
      ],
      "reference_answer": "Football",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Football": 0.9460652218268183
      },
      "individual_log_probs": {
        "Football": -0.055443767458200455
      },
      "max_prob": 0.9460652218268183,
      "max_log_prob": -0.055443767458200455,
      "best_answer": "Football",
      "total_prob": 0.9460652218268183,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 83,
      "generated_answer": "Betty X",
      "gold_answers": [
        "Betty X"
      ],
      "reference_answer": "Betty X",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Betty X": 0.8967835608841768
      },
      "individual_log_probs": {
        "Betty X": -0.10894073825284067
      },
      "max_prob": 0.8967835608841768,
      "max_log_prob": -0.10894073825284067,
      "best_answer": "Betty X",
      "total_prob": 0.8967835608841768,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 84,
      "generated_answer": "Extreme Pizza",
      "gold_answers": [
        "Extreme Pizza"
      ],
      "reference_answer": "Extreme Pizza",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Extreme Pizza": 0.987490676802326
      },
      "individual_log_probs": {
        "Extreme Pizza": -0.012588223464263137
      },
      "max_prob": 0.987490676802326,
      "max_log_prob": -0.012588223464263137,
      "best_answer": "Extreme Pizza",
      "total_prob": 0.987490676802326,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 85,
      "generated_answer": "Anna Mae Bullock",
      "gold_answers": [
        "Anna Mae Bullock"
      ],
      "reference_answer": "Anna Mae Bullock",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Anna Mae Bullock": 0.994876150752481
      },
      "individual_log_probs": {
        "Anna Mae Bullock": -0.005137021176324197
      },
      "max_prob": 0.994876150752481,
      "max_log_prob": -0.005137021176324197,
      "best_answer": "Anna Mae Bullock",
      "total_prob": 0.994876150752481,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 86,
      "generated_answer": "Michie Stadium",
      "gold_answers": [
        "Michie Stadium"
      ],
      "reference_answer": "Michie Stadium",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Michie Stadium": 0.9994961166962814
      },
      "individual_log_probs": {
        "Michie Stadium": -0.0005040102955717884
      },
      "max_prob": 0.9994961166962814,
      "max_log_prob": -0.0005040102955717884,
      "best_answer": "Michie Stadium",
      "total_prob": 0.9994961166962814,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 87,
      "generated_answer": "Pacific Ocean",
      "gold_answers": [
        "the Pacific Ocean"
      ],
      "reference_answer": "the Pacific Ocean",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "the Pacific Ocean": 0.00016084067848048662
      },
      "individual_log_probs": {
        "the Pacific Ocean": -8.73509625758743
      },
      "max_prob": 0.00016084067848048662,
      "max_log_prob": -8.73509625758743,
      "best_answer": "the Pacific Ocean",
      "total_prob": 0.00016084067848048662,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 88,
      "generated_answer": "Angela Nissel",
      "gold_answers": [
        "Angela R. Nissel"
      ],
      "reference_answer": "Angela R. Nissel",
      "em_score": 0.0,
      "f1_score": 0.8,
      "precision": 1.0,
      "recall": 0.6666666666666666,
      "individual_probs": {
        "Angela R. Nissel": 1.720332940418627e-09
      },
      "individual_log_probs": {
        "Angela R. Nissel": -20.180747994842477
      },
      "max_prob": 1.720332940418627e-09,
      "max_log_prob": -20.180747994842477,
      "best_answer": "Angela R. Nissel",
      "total_prob": 1.720332940418627e-09,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 89,
      "generated_answer": "LyondellBasell.",
      "gold_answers": [
        "Netherlands"
      ],
      "reference_answer": "Netherlands",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Netherlands": 0.029599746103242723
      },
      "individual_log_probs": {
        "Netherlands": -3.5199894952820614
      },
      "max_prob": 0.029599746103242723,
      "max_log_prob": -3.5199894952820614,
      "best_answer": "Netherlands",
      "total_prob": 0.029599746103242723,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 90,
      "generated_answer": "Alessandro Nannini",
      "gold_answers": [
        "Alessandro Nannini"
      ],
      "reference_answer": "Alessandro Nannini",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Alessandro Nannini": 0.9326216980402868
      },
      "individual_log_probs": {
        "Alessandro Nannini": -0.06975562869769192
      },
      "max_prob": 0.9326216980402868,
      "max_log_prob": -0.06975562869769192,
      "best_answer": "Alessandro Nannini",
      "total_prob": 0.9326216980402868,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 91,
      "generated_answer": "Theo van Gogh",
      "gold_answers": [
        "Theodorus \"Theo\" van Gogh"
      ],
      "reference_answer": "Theodorus \"Theo\" van Gogh",
      "em_score": 0.0,
      "f1_score": 0.8571428571428571,
      "precision": 1.0,
      "recall": 0.75,
      "individual_probs": {
        "Theodorus \"Theo\" van Gogh": 3.250523517994717e-08
      },
      "individual_log_probs": {
        "Theodorus \"Theo\" van Gogh": -17.241864678123193
      },
      "max_prob": 3.250523517994717e-08,
      "max_log_prob": -17.241864678123193,
      "best_answer": "Theodorus \"Theo\" van Gogh",
      "total_prob": 3.250523517994717e-08,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 92,
      "generated_answer": "Indian Rebellion of 1857",
      "gold_answers": [
        "Indian Rebellion of 1857"
      ],
      "reference_answer": "Indian Rebellion of 1857",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Indian Rebellion of 1857": 0.5984079166306455
      },
      "individual_log_probs": {
        "Indian Rebellion of 1857": -0.5134826227458689
      },
      "max_prob": 0.5984079166306455,
      "max_log_prob": -0.5134826227458689,
      "best_answer": "Indian Rebellion of 1857",
      "total_prob": 0.5984079166306455,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 93,
      "generated_answer": "Yes.",
      "gold_answers": [
        "yes"
      ],
      "reference_answer": "yes",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "yes": 0.0007552089137906185
      },
      "individual_log_probs": {
        "yes": -7.188516139984131
      },
      "max_prob": 0.0007552089137906185,
      "max_log_prob": -7.188516139984131,
      "best_answer": "yes",
      "total_prob": 0.0007552089137906185,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 94,
      "generated_answer": "Ludovico Einaudi collaborated with Canzoniere Grecanico Salentino on notable performances.",
      "gold_answers": [
        "Italian pianist and composer"
      ],
      "reference_answer": "Italian pianist and composer",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Italian pianist and composer": 1.5367637498565688e-10
      },
      "individual_log_probs": {
        "Italian pianist and composer": -22.596172185814794
      },
      "max_prob": 1.5367637498565688e-10,
      "max_log_prob": -22.596172185814794,
      "best_answer": "Italian pianist and composer",
      "total_prob": 1.5367637498565688e-10,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 95,
      "generated_answer": "Daesung",
      "gold_answers": [
        "actress"
      ],
      "reference_answer": "actress",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "actress": 3.560471711541716e-05
      },
      "individual_log_probs": {
        "actress": -10.243032425642014
      },
      "max_prob": 3.560471711541716e-05,
      "max_log_prob": -10.243032425642014,
      "best_answer": "actress",
      "total_prob": 3.560471711541716e-05,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 96,
      "generated_answer": "Amsterdam",
      "gold_answers": [
        "Amsterdam"
      ],
      "reference_answer": "Amsterdam",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Amsterdam": 0.9949547217890754
      },
      "individual_log_probs": {
        "Amsterdam": -0.005058048598584719
      },
      "max_prob": 0.9949547217890754,
      "max_log_prob": -0.005058048598584719,
      "best_answer": "Amsterdam",
      "total_prob": 0.9949547217890754,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 97,
      "generated_answer": "Yes.",
      "gold_answers": [
        "no"
      ],
      "reference_answer": "no",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "no": 8.507163372023079e-05
      },
      "individual_log_probs": {
        "no": -9.372016906738281
      },
      "max_prob": 8.507163372023079e-05,
      "max_log_prob": -9.372016906738281,
      "best_answer": "no",
      "total_prob": 8.507163372023079e-05,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 98,
      "generated_answer": "Nickelodeon",
      "gold_answers": [
        "Nickelodeon"
      ],
      "reference_answer": "Nickelodeon",
      "em_score": 1.0,
      "f1_score": 1.0,
      "precision": 1.0,
      "recall": 1.0,
      "individual_probs": {
        "Nickelodeon": 0.9961464047236626
      },
      "individual_log_probs": {
        "Nickelodeon": -0.003861039505466124
      },
      "max_prob": 0.9961464047236626,
      "max_log_prob": -0.003861039505466124,
      "best_answer": "Nickelodeon",
      "total_prob": 0.9961464047236626,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    },
    {
      "sample_idx": 99,
      "generated_answer": "On the Road with Austin and Santino.",
      "gold_answers": [
        "Project Runway"
      ],
      "reference_answer": "Project Runway",
      "em_score": 0.0,
      "f1_score": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "individual_probs": {
        "Project Runway": 0.05042814940778272
      },
      "individual_log_probs": {
        "Project Runway": -2.9872057398233665
      },
      "max_prob": 0.05042814940778272,
      "max_log_prob": -2.9872057398233665,
      "best_answer": "Project Runway",
      "total_prob": 0.05042814940778272,
      "answer_count": 1,
      "valid_answer_count": 1,
      "weight_w": 0.3
    }
  ]
}